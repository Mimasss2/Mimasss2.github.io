<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>NLP可控文本生成评价指标</title>
    <link href="/NLP%E5%8F%AF%E6%8E%A7%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <url>/NLP%E5%8F%AF%E6%8E%A7%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<h2 id="句子层面">句子层面</h2><h3 id="bleu">BLEU</h3><p><strong>评价句子之间的字面相似度。</strong>基于翻译任务，对候选翻译与参考文本中的相匹配的 n元组进行计数，其中一元组 (1-gram/ unigram) 比较的是每一个<strong>单词</strong>，而二元组 (bigram) 比较的则是每个单词对，以此类推，并且这种比较是不管单词顺序的。匹配个数越多，表明候选翻译的质量就越好。</p><p>生成句子和参考句子的单词/n元组重复度，评分越高。即句子的<strong>字面义</strong>越相近，BLUE分数越高。</p><h3 id="rouge">ROUGE</h3><p><strong>评价句子之间的字面相似度。</strong>与 BLEU类似，通过统计生成的句子与参考句子集合之间重叠的基本单元（n元组）的数目来评估生成句子的质量。使用召回率作为指标。</p><p><a href="https://xiaosheng.run/2020/08/13/calculate-bleu-and-rouge.html">用 Python 计算文本 BLEU 分数和 ROUGE 值</a></p><h3 id="meteor">METEOR</h3><p><strong>评价句子之间的语义相似性。</strong>在BLEU的基础上改进，使用WordNet计算序列匹配、同义词、词根和词缀，释义之间的匹配关系，基于F1值。并使用句子的chunk计算惩罚项，惩罚较长的句子。</p><blockquote><p>不过看之前的可控文本生成的工作中基本都没有用这个指标。</p></blockquote><h3 id="dist-n">Dist-n</h3><p><strong>评价句子内部的字面多样性。</strong>从单词/n-gram层面评价文本的多样性。评分越高，表示多样性越高。</p><p><a href="https://arxiv.org/pdf/1510.03055.pdf">A Diversity-Promoting Objective Function for Neural Conversation Models</a></p><p><span class="math display">\[Distinct = \frac{Different \ n-gram}{Total \ n-gram}\]</span></p><h3 id="perplexity">Perplexity</h3><p><strong>评价句子的流利度。</strong>通过计算句子每个词的概率的乘积的开方，表示句子的流利度。指标越小，句子的流利度越高。</p><h3 id="blueurt">BLUEURT</h3><p><strong>评价句子之间的语义相似性。</strong>由Google Research提出，用WMT任务的数据集，在ERT上训练的一个learned metric，评价句子之间的<strong>语义相似度。</strong>分数越高，生成的句子和原句子越相似。</p><h3 id="ctrleval">CTRLEval</h3><p>来自清华CoAI，是一个无监督的句子评价指标，针对可控文本生成，从多个角度给句子评分。使用text-infilling方法来引导LM（PEGASUS）生成相应内容，并以其概率作为分数。使用不同的text-infilling模板，将结果加权，使最终结果更加准确。</p><p>评价的维度：</p><ul><li>coherence</li><li>consistency</li><li>attribute relevance （前提：attribute要可以被转化为自然语言）</li></ul><p><a href="https://aclanthology.org/2022.acl-long.164/">CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation</a></p><figure><img src="/img/NLP可控文本生成评价指标/Untitled.png" alt="CTRLEval结构" /><figcaption aria-hidden="true">CTRLEval结构</figcaption></figure><h3 id="gruen">GRUEN</h3><p>来自伊利诺伊香槟，是一个无监督的句子评价指标。</p><p><a href="https://aclanthology.org/2020.findings-emnlp.9/">GRUEN for Evaluating Linguistic Quality of Generated Text</a></p><p>评价的维度：</p><ul><li>Grammaticality：<ul><li>分别把句子中的每个词换成mask，计算原词的概率</li><li>用BERT训练一个分类器，分类为grammatical/ungrammatical, grammatical的概率即为分数</li></ul></li><li>Non-redundancy<ul><li>指代重复，内容重复等</li></ul></li><li>Focus<ul><li>一段文本，连续的两个句子之间的语义连贯性</li></ul></li><li>Structure and coherence<ul><li>Sentence-Order Prediction loss</li><li>一段文本分成两个部分，交换次序后计算logistic loss</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Gumbel Softmax 的原理与应用</title>
    <link href="/Gumbel-Softmax-%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/"/>
    <url>/Gumbel-Softmax-%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>Gumbel Softmax是一种离散情形下，计算损失的一种重参数技巧。将原本不可导的采样函数转化为可导的,便于深度神经网络的训练。此方法首次提出于<a href="https://arxiv.org/abs/1611.01144">Categorical Reparameterization with Gumbel-Softmax</a>和<a href="https://arxiv.org/abs/1611.00712">The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</a>。Gumbel Softmax在实践中比其他的采样器效果更好，可以有效的训练半监督模型。</p><span id="more"></span><h2 id="为什么要使用gumbel-softmax">为什么要使用Gumbel Softmax</h2><p>在NLP领域中，文本是由离散的词组成的，每个词在训练过程中有着对应的embedding。当我们需要模型生成词的时候，常见的操作是对模型的输出进行softmax操作，使概率的总和为1，且最可能的词的概率逼近1。这样处理后使用交叉熵计算loss，而得到的向量近似于one-hot向量，在进行argmax操作后得到预测的词。然而在argmax操作这一步，函数是不可导的，这就导致在这之后的神经网络的梯度无法回传，这就导致了严重的问题，比如说利用GAN生成句子时，判别器的梯度无法回传至编码器。</p><p>比如说，我们有一个词汇表：<code>cat, dog, fish, deer</code>，LM在某一步的输出为<span class="math inline">\([-20, 10, 9.6 6.2]\)</span>，那么此时第2个维度值最大，预测出的词便是dog。选择词的这一步，隐向量从<span class="math inline">\([-20, 10, 9.6 6.2]\)</span>变为<span class="math inline">\([0,1,0,0]\)</span>，这并不是一个可导的函数，无法计算梯度，更新参数。也就是说，词的选择没有体现出概率的真实含义，比如在概率分布<span class="math inline">\([0,0.591,0.396,0.013]\)</span>和<span class="math inline">\([0,0.9,0.1,0]\)</span>下，我们最终选择的都是<code>dog</code>。</p><p>假设我们是输出为<span class="math inline">\(y\)</span>，<span class="math inline">\(y\)</span>的分布依赖于参数<span class="math inline">\(\theta\)</span>，损失函数为<span class="math inline">\(f(y)\)</span>，那么loss的期望值为 <span class="math display">\[L_{\theta} = E_{y\thicksim p(y|\theta)}[f(y)] = \underset{y}{\Sigma} p(y|\theta)f(y)\]</span> 在离散情形下，<span class="math inline">\(p(y|\theta)\)</span>是离散概率分布，即取值情况是有限的。在上例中，只有4种情况。但当类别数目增多后，直接通过枚举，求和，计算量是巨大的，因此我们需要通过采样来对损失函数进行有效估计，同时不能损失梯度信息。</p><p>为了体现概率的真实含义，比较直接的一个方法是，直接根据概率分布采样，生成样本，再用样本去计算loss，作为loss函数的期望。为此，便有了Gumbel Max，一个从类别中采样的方法，并在其中引入随机变量，把分布的随机性转移到随机变量上。</p><p>但这样处理，也有一个问题，采样过程涉及argmax函数，还是不可导的（比如说决策函数是分段函数），不可导意味着梯度在这一步无法传递。</p><p>在这个基础上，再引入Gumbel Softmax，即对其使用softmax，得到Gumbel Max的光滑近似。在这一步，又引入了一个温度变量，来控制结果与one-hot向量的接近度和gradient vanishment。</p><p>简而言之，在离散分布的情况下，常用的softmax倾向于让最大值的概率显著大于其他值，并没有很好的体现概率的含义。因此提出了Gumbel Max使得概率分布可以更好地采样，同时采样函数关于原分布参数<span class="math inline">\(\theta\)</span>是可导的，保留了梯度。而Gumbel Softmax则是对Gumbel Max的光滑近似。</p><h2 id="原理">原理</h2><p>重参数主要解决了采样过程对于概率分布参数不可导的问题，而Gumbel Softmax则是具体到离散分布下，重参数的一种方法。</p><h3 id="重参数re-parameterization-trick">重参数(Re-parameterization Trick)</h3><p>重参数是处理计算损失函数的期望的一种技巧，即： <span class="math display">\[L_{\theta} = E_{y\thicksim (y|\theta)}[f(y)]\]</span> 这在VAE、GAN、Reinforcement Learning中都有出现。</p><p>在大多数情况下，我们无法精确的计算出期望，而只能通过采样，对期望进行估算。而重参数便是一种采样方式，在拟合<span class="math inline">\(p(y|\theta)\)</span>的同时，保留<span class="math inline">\(\theta\)</span>的梯度。</p><p>当<span class="math inline">\(p(y|\theta)\)</span>是连续函数时，可将采样转化为两个步骤：</p><ol type="1"><li>从无参数分布<span class="math inline">\(q(\epsilon)\)</span>中采样一个<span class="math inline">\(\epsilon\)</span></li><li>用一个连续可导函数<span class="math inline">\(g_{\theta}(\epsilon)\)</span>生成样本<span class="math inline">\(y\)</span>，即<span class="math inline">\(y = g_{\theta}(\epsilon)\)</span></li></ol><p>那么，上面提到的期望函数便可转化为： <span class="math display">\[L_{\theta} = E_{\epsilon\thicksim q(\epsilon)}[f(g_{\theta}(\epsilon))] \]</span></p><p>也就是说，我们将采样的过程转移到无参数分布，便解决了概率分布参数<span class="math inline">\(\theta\)</span>在采样过程中不可导的问题。</p><figure><img src="/img/Gumbel-Softmax-的原理与应用/sample-in-net.png" alt="re-parameterization in neutal network" /><figcaption aria-hidden="true">re-parameterization in neutal network</figcaption></figure><p>上图演示了梯度估计中常见的几种方法。最右边的图即为gumbel-softmax的过程，其中<span class="math inline">\(\theta\)</span>为概率分布的参数，<span class="math inline">\(g\)</span>为无参数分布采样的随机变量变换后端的结果。我们将不可导的过程从原先的直接采样，移动到了无参数分布采样的过程。而无参数分布采样并不影响网络梯度的计算。</p><p>举个例子，如果我们要采样的分布为正态分布，均值为<span class="math inline">\(\mu\)</span>，标准差为<span class="math inline">\(\sigma\)</span>，<span class="math inline">\(\theta = \{ \mu, \sigma \}\)</span>，那么<span class="math inline">\(p(y|theta) = p(y|\mu,\theta)\)</span>。此时利用重参数化进行采样，步骤为：</p><ol type="1"><li>从无参数分布<span class="math inline">\(N (\epsilon ; 0, 1)（均值为0，标准差为1的正态分布）中采样\epsilon\)</span>。</li><li><span class="math inline">\(g_{\mu, \sigma}(\epsilon) = \sigma \epsilon + \mu\)</span>。此函数对<span class="math inline">\(\mu, \sigma\)</span>均可导。</li></ol><p>然而离散分布的重参数化比连续分布的重参数化难得多，Gumbel Softmax便实现了离散分布的重参数化。</p><h3 id="gumbel-softmax">Gumbel Softmax</h3><p>Gumbel Softmax提供了一种从离散（类别）分布中采样的方法。</p><p>我们首先介绍Gumbel Max。</p><p>假设有n个类，每个类的概率分别时<span class="math inline">\(p_1, p_2, ..., p_n\)</span>，那么在Gumbel Max下依次概率采样的方案为： <span class="math display">\[\underset{i}{argmax} (log p_i + G_i), Gi = -log(-log \epsilon_i), \epsilon_i \thicksim U[0,1]\]</span></p><p>其中<span class="math inline">\(G_i\)</span>是独立同分布的标准Gumbel分布的随机变量。</p><p>如此便实现了重参数化，将采样的随机性丢给<span class="math inline">\(\epsilon_i\)</span>，我们在下一部分证明这个过程等价于原概率的采样。</p><p>但是，这样还是丢失了梯度信息，因为argmax不可导。因此，我们借鉴神经网络中的softmax，对Gumbel Max做光滑近似：</p><p><span class="math display">\[softmax((log p_i + G_i)/\tau), Gi = -log(-log \epsilon_i), \epsilon_i \thicksim U[0,1]\]</span></p><p>其中参数<span class="math inline">\(\tau\)</span>为温度，它越小越接近one-hot，但同时gradient vanishing也更加严重；它越大越接近均匀分布，如下图所示。</p><figure><img src="\img\Gumbel-Softmax-的原理与应用\temperature.png" alt="gumbel softmax分布与温度的关系" /><figcaption aria-hidden="true">gumbel softmax分布与温度的关系</figcaption></figure><p>相比原来直接使用softmax，gumbel分布的引入有机会产生非最大值位置的one-hot向量，增加了随机性，有助于提高训练效果。</p><h2 id="gumbel-max的数学证明4">Gumbel Max的数学证明<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://www.spaces.ac.cn/archives/6705">[4]</span></a></sup></h2><p>假设在Gumbel Max下，有n个类别，采样方案为： <span class="math display">\[\underset{i}{argmax} (log p_i + G_i), \quad Gi = -log(-log \epsilon_i), \quad \epsilon_i \thicksim U[0,1]\]</span> 那么输出类别k时，意味着： <span class="math display">\[log p_k - log(-log \epsilon_k) &gt; log p_j - log(-log \epsilon_j), j \neq k\]</span> 化简得到： <span class="math display">\[\epsilon_j &lt; \epsilon_k^{p_j/p_k} \leq 1\]</span> 由于<span class="math inline">\(epsilon_j ~ U[0,1]\)</span>，此不等式成立的概率为<span class="math inline">\(\epsilon_k^{p_j/p_k}\)</span>。 那么，所有n-1个不等式都成立的条件为： <span class="math display">\[\epsilon_k^{p_1/p_k} \cdots \epsilon_k^{p_{k-1}/p_k} \epsilon_k^{p_{k+1}/p_k} \cdots \epsilon_k^{p_n/p_k} = \epsilon_k^{(1-p_k)/p_k}\]</span> <span class="math display">\[\int_0^1 \epsilon_k^{(1-p_k)/p_k} = p_k\]</span></p><p>即，输出类别k的概率为p_k，与原概率分布一致。</p><h2 id="应用">应用</h2><p>pytorch中封装了Gumbel Softmax<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#gumbel_softmax">[6]</span></a></sup>，源代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gumbel_softmax</span>(<span class="hljs-params">logits: Tensor, tau: <span class="hljs-built_in">float</span> = <span class="hljs-number">1</span>, hard: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>, eps: <span class="hljs-built_in">float</span> = <span class="hljs-number">1e-10</span>, dim: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span></span>) -&gt; Tensor:<br>    <span class="hljs-string">r&quot;&quot;&quot;</span><br><span class="hljs-string">    Samples from the Gumbel-Softmax distribution (`Link 1`_  `Link 2`_) and optionally discretizes.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">      logits: `[..., num_features]` unnormalized log probabilities</span><br><span class="hljs-string">      tau: non-negative scalar temperature</span><br><span class="hljs-string">      hard: if ``True``, the returned samples will be discretized as one-hot vectors,</span><br><span class="hljs-string">            but will be differentiated as if it is the soft sample in autograd</span><br><span class="hljs-string">      dim (int): A dimension along which softmax will be computed. Default: -1.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">      Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.</span><br><span class="hljs-string">      If ``hard=True``, the returned samples will be one-hot, otherwise they will</span><br><span class="hljs-string">      be probability distributions that sum to 1 across `dim`.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    .. note::</span><br><span class="hljs-string">      this function is here for legacy reasons, may be removed from nn.Functional in the future.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    .. note::</span><br><span class="hljs-string">      The main trick for `hard` is to do  `y_hard - y_soft.detach() + y_soft`</span><br><span class="hljs-string"></span><br><span class="hljs-string">      It achieves two things:</span><br><span class="hljs-string">      - makes the output value exactly one-hot</span><br><span class="hljs-string">      (since we add then subtract y_soft value)</span><br><span class="hljs-string">      - makes the gradient equal to y_soft gradient</span><br><span class="hljs-string">      (since we strip all other gradients)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> has_torch_function_unary(logits):<br>        <span class="hljs-keyword">return</span> handle_torch_function(gumbel_softmax, (logits,), logits, tau=tau, hard=hard, eps=eps, dim=dim)<br>    <span class="hljs-keyword">if</span> eps != <span class="hljs-number">1e-10</span>:<br>        warnings.warn(<span class="hljs-string">&quot;`eps` parameter is deprecated and has no effect.&quot;</span>)<br><br>    gumbels = (<br>        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()<br>    )  <span class="hljs-comment"># ~Gumbel(0,1)</span><br>    gumbels = (logits + gumbels) / tau  <span class="hljs-comment"># ~Gumbel(logits,tau)</span><br>    y_soft = gumbels.softmax(dim)<br><br>    <span class="hljs-keyword">if</span> hard:<br>        <span class="hljs-comment"># Straight through.</span><br>        index = y_soft.<span class="hljs-built_in">max</span>(dim, keepdim=<span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>]<br>        y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, <span class="hljs-number">1.0</span>)<br>        ret = y_hard - y_soft.detach() + y_soft<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># Reparametrization trick.</span><br>        ret = y_soft<br>    <span class="hljs-keyword">return</span> ret<br><br></code></pre></td></tr></table></figure><p>当hard参数为True时，返回是one-hot向量，但是在梯度更新的时候，使用Gumbel softmax平滑后的概率分布计算。当hard参数为True时，返回的是Gumbel Softmax处理后的概率分布。</p><section class="footnotes"><h2>参考</h2><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://arxiv.org/abs/1611.01144">Categorical Reparameterization with Gumbel-Softmax</a> <a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>[The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables]{https://arxiv.org/abs/1611.00712} <a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>https://www.cnblogs.com/initial-h/p/9468974.html <a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>https://www.spaces.ac.cn/archives/6705 <a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:5" class="footnote-text"><span>https://blog.evjang.com/2016/11/tutorial-categorical-variational.html <a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:6" class="footnote-text"><span>https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#gumbel_softmax <a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP, Gumbel-Softmax</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读 | Fine-Grained Sentiment-Controlled Text Generation Approach Based on Pre-Trained Language Model</title>
    <link href="/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fine-Grained-Sentiment-Controlled-Text-Generation-Approach-Based-on-Pre-Trained-Language-Model/"/>
    <url>/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Fine-Grained-Sentiment-Controlled-Text-Generation-Approach-Based-on-Pre-Trained-Language-Model/</url>
    
    <content type="html"><![CDATA[<p>本文主要介绍了一种细粒度可控文本生成的方法，发表在<em>Applied Science</em>上，来自浙江工业大学。</p><span id="more"></span><p>可控文本生成的研究大多聚焦与文章级别或句子级别的情感控制，而在细粒度情感控制，如具体到aspect, opinion, polarity方面的比较少，这是由此类数据集的稀缺性导致的。本文提出了一个细粒度可控文本生成模型，并辅之以提取细粒度情感信息的分类器，以利用大规模无标签的数据。本文的贡献主要如下：</p><ul><li>借助现有的transformer模型，引入查询提示机制和情感控制损失，进一步在细粒度级别控制文本生成。</li><li>引入aspect-opinion对作为细粒度情感单元，进行可控文本生成</li><li>辅之以提取细粒度情感信息的分类器，利用大规模无标注数据对模型进行训练，提高模型性能和泛化能力。</li></ul><h2 id="训练模式">训练模式</h2><ol type="1"><li>用有标注的数据集训练生成器和判别器</li><li>用第1步训练的判别器，为大规模无标注语料生成伪标签。</li><li>用带伪标签的大规模数据训练生成器。</li><li>用有标注的数据集对生成器进一步微调。</li></ol><h2 id="生成器结构">生成器结构</h2><p>沿用GPT-2 medium的模型架构，将细粒度情感信息(aspect-opinion pair)和句子拼接，作为输入。同时，微调注意力机制，避免细粒度情感信息（提示）在生成较后部分的句子使对生成的词的提示（约束）有限。</p><p>生成器的结构示意图如下：</p><p><img src="\img\论文阅读-Fine-Grained-Sentiment-Controlled-Text-Generation-Approach-Based-on-Pre-Trained-Language-Model\generator-architecture.png" /></p><p>对注意力机制进行微调：对于key, value, query矩阵<span class="math inline">\((K, V, Q&#39; \in R^{(l_s+t)\times d}, l_s, t是附加的情感控制信息、普通句子的长度)\)</span>，隐向量<span class="math inline">\(h = [h^0;h^1], h^0,h^1\)</span>分别是情感控制信息，普通句子的隐向量。对原query矩阵<span class="math inline">\(Q\)</span>进行微调，得到<span class="math inline">\(Q&#39;\)</span>作文新的query矩阵，计算方法如下： <span class="math display">\[Q = [Q^0; Q^1] = h \times W_q^T, \quad K = [K^0; K^1] = h \times W_k^T\]</span> <span class="math display">\[Q&#39; = [Q^0; Q&#39;^{1}] Q&#39;^{1} = f_{hint}(K^0,Q^1) \times W_{q&#39;}^T\]</span></p><p><span class="math display">\[\begin{equation}  f_{hint}(K^0, Q^1) = Q^1 + M_h \times   \left[    \begin{array}{c}        Mean(K_{0:l_1}) \\    Mean(K_{l_1:l_2}) \\    \cdots \\    Mean(K_{l_{n-1}:l_n}) \\    \end{array}\right]\end{equation}\]</span></p><p>其中<span class="math inline">\(K_{l_{i-1}:l_i}\)</span>对应第i个aspect-opinion pair的K矩阵行的平均。<span class="math inline">\(M_h \in R_{t\times n}\)</span>是邻接矩阵。</p><p>这样处理的目的是，将情感控制信息的表示添加到句子部分的query中，利用<span class="math inline">\(M_h\)</span>控制句子生成时，具体参照哪一对aspect-opinion的信息。</p><h2 id="查询提示机制">查询提示机制</h2><p>在GPT-2中，当前位置前面的所有词对于生成具有同等重要性。而在可控文本生成的场景下，显然情感控制信息中的部分更加重要。因此，引入查询提示机制，控制不同位置处，不同部分的情感控制信息（不同的aspect-opinion pair）的重要性，具体来讲分为以下几点：</p><ol type="1"><li>一个一个pair按顺序来，每次只refer一个pair。</li><li>当pair中的部分词/信息已被满足时，不再提示此词。</li><li>若某个aspect/opinion对应于多个词，则提示时，按词的顺序依次显示（变为可见）。</li><li>未生成任何与提示词直接相关的词的时候，此pair的aspect和opinion（的第一个词）均可见。</li></ol><p>查询提示机制的图示如下：</p><p><img src="\img\论文阅读-Fine-Grained-Sentiment-Controlled-Text-Generation-Approach-Based-on-Pre-Trained-Language-Model\query-hint-mechanism.png" /></p><h2 id="损失函数的设计">损失函数的设计</h2><p>损失函数 = 生成句子的损失函数（交叉熵损失）+ 情感控制损失函数</p><p>情感控制损失函数的设置，是为了提高生成的句子和情感控制信息的契合度。具体来讲就是最大化aspect/opinion词处的概率，定义如下：</p><p><span class="math display">\[L_{Senti} = L_a + L_o\]</span> <span class="math display">\[L_a = -\underset{a}{\Sigma} \underset{t}{\Sigma} \log [Q(x&#39; Mask_{a,t})]_{I^x(x_{a,t})}\]</span> <span class="math display">\[L_o = -\underset{p}{\Sigma} \underset{t}{\Sigma} \log [Q(x&#39; Mask_{o,t})]_{I^x(x_{o,t})}\]</span> <span class="math display">\[Q(x,Mask) = Mask \odot p_{max}(x) + (1 \oplus Mask) \times \theta_{mean}\]</span> <span class="math display">\[p_{max}(x) = MaxPooling ([p(x_1| s, x_{:0}); p(x_2|s,x_{:1});\cdots; p(x_t|s,x_{:t-1})])\]</span></p><p>其中<span class="math inline">\(L_a, L_o\)</span> 分别是对应于aspect和opinion的损失函数。Mask 是独热向量，只有aspect/opinion词处为1。<span class="math inline">\(\phi_{mean}\)</span>是一个超参数，控制aspect/opinion的信息被增强的程度。</p><p>总体上， <span class="math inline">\(L_{total} = \lambda_G L_G + \lambda_{Senti} L_{Senti}\)</span>.</p><h2 id="分类器的设计">分类器的设计</h2><p>分类器的总体架构如下图所示。</p><p><img src="\img\论文阅读-Fine-Grained-Sentiment-Controlled-Text-Generation-Approach-Based-on-Pre-Trained-Language-Model\classifier-architecture.png" /></p><p>首先，用卷积神经网络，以不同粒度对原始句子进行编码。将不同粒度的编码拼接，再进行两次卷积，得到句子的编码。 进而，用双向LSTM对句子进行编码。再加入attention，进一步对句子编码。 下一步，将aspect和opinion的隐向量和转移状态的向量拼接，形成一个二维的表格态的表示。对其利用线性分类器进行分类，提取处有效的aspect和opinion对。</p><h2 id="评价指标">评价指标</h2><ul><li><strong>流利度：</strong> BLEU, ROUGE, METEOR （需参考原始句子）</li><li><strong>多样性：</strong> Dist-1,-2,-3, Self-Bleu</li><li><strong>情感匹配度：</strong><ul><li>Coverage: aspect, opinion, aspect-opinion</li><li>Accuracy(使用训练的判别器进行评判，结果不完全精确)</li></ul></li></ul><h2 id="相关工作待阅读">相关工作(待阅读)</h2><h3 id="可控文本生成">可控文本生成</h3><ol type="1"><li><p>SeqGAN <sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient">[2]</span></a></sup></p><p>将生成模型看作RL中的agent，state对应已生成的token，action是下一个要生成的token。使用policy gradient，MC search来逼近state-action的值，缓解离散词向量和GAN训练方式的出入。</p></li><li><p>conditional generative model</p><p><sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="Controlling Output Length in Neural Encoder-Decoders">[3]</span></a></sup> 在hidden state中加入长度的embedding; <sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Controlling Linguistic Style Aspects in Neural Language Generation">[4]</span></a></sup> 对每类style做一个embedding矩阵，不同类style的embedding拼接在一起后，作为RNN的输入</p></li><li><p>Reinforcement Learning <sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fine-Tuning Language Models from Human Preferences">[5]</span></a></sup></p></li><li><p>Conditional-Transformer-Language model(various control codes) <sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="A Conditional Transformer Language Model for Controllable Generation">[6]</span></a></sup></p></li><li><p>PPLM: with pluggable attribute controllers <sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="Plug and Play Language Models: A Simple Approach to Controlled Text Generation">[7]</span></a></sup></p><p>在LM后加一个attribute model，用BoW（Bag of Words）拟合生成的句子部分对于attribute的拟合度。更新梯度时，只更新之前生成的一部分句子的key和value matrix（与之后生成的句子部分的attention相关），以此引导后面部分句子的内容向attribute靠拢。</p></li><li><p>Content-Conditional (target control) <sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span class="hint--top hint--rounded" aria-label="CoCon: A Self-Supervised Approach for Controlled Text Generation">[8]</span></a></sup></p></li><li><p>infusing attribute representation to LM <sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><span class="hint--top hint--rounded" aria-label="Attribute Alignment: Controlling Text Generation from Pre-trained Language Models">[9]</span></a></sup></p></li></ol><h3 id="评论生成">评论生成</h3><ol type="1"><li><p>A2T(Attribute-to-Text) <sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><span class="hint--top hint--rounded" aria-label="Learning to Generate Product Reviews from Attributes">[10]</span></a></sup></p><p><sup id="fnref:11" class="footnote-ref"><a href="#fn:11" rel="footnote"><span class="hint--top hint--rounded" aria-label="Cyclic consistency based product review generator from attributes">[11]</span></a></sup> 将特征转化为独热编码，进一步编码后作为LSTM的初始hidden state。注意力机制，用来参照不同的特征</p></li><li><p>AT2T(Attribute-matched-Text-to-Text) <sup id="fnref:12" class="footnote-ref"><a href="#fn:12" rel="footnote"><span class="hint--top hint--rounded" aria-label="Retrieval-Augmented Controllable Review Generation">[12]</span></a></sup></p></li></ol><h3 id="情感级可控文本生成">情感级可控文本生成</h3><ol type="1"><li><p>on aspect-sentiment scores <sup id="fnref:13" class="footnote-ref"><a href="#fn:13" rel="footnote"><span class="hint--top hint--rounded" aria-label="Towards Automatic Generation of Product Reviews from Aspect-Sentiment Scores">[13]</span></a></sup></p><p>用了hierarchical的架构，有一个文章LSTM(P-LSTM)和句子LSTM(S-LSTM)。</p><ul><li>特征向量作为P-LSTM的起始状态。</li><li>每个方面的句子对应一个S-LSTM</li><li>上一句的S-LSTM的终态和上一个P-LSTM的hidden state 作gated 后，作为下一个P-LSTM的cell 的hidden state</li></ul></li><li><p>semi-supervise training -- leverage large-scale unlabeled data <sup id="fnref:14" class="footnote-ref"><a href="#fn:14" rel="footnote"><span class="hint--top hint--rounded" aria-label="Aspect-Level Sentiment-Controllable Review Generation with Mutual Learning Framework">[14]</span></a></sup></p><p>mutual learning 来利用大规模无标注数据，有点像GAN的思想。用confidence mechanism（伪标签的置信度）作为判别器对生成器的反馈，作用于生成器的损失项；用reconstruction reward（在伪标签条件下生成句子的perplexity）作为生成器对判别器的反馈。</p></li><li><p>dual learning system (+classifier) <sup id="fnref:15" class="footnote-ref"><a href="#fn:15" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mutual disentanglement learning for joint fine-grained sentiment classification and controllable text generation">[15]</span></a></sup></p></li><li><p>HTT opinion generation &amp; review composition <sup id="fnref:16" class="footnote-ref"><a href="#fn:16" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hierarchical template transformer for fine-grained sentiment controllable generation">[16]</span></a></sup></p></li></ol><section class="footnotes"><h2>参考</h2><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Fine-Grained Sentiment-Controlled Text Generation Approach Based on Pre-Trained Language Model <a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient <a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>Controlling Output Length in Neural Encoder-Decoders <a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>Controlling Linguistic Style Aspects in Neural Language Generation <a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:5" class="footnote-text"><span>Fine-Tuning Language Models from Human Preferences <a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:6" class="footnote-text"><span>A Conditional Transformer Language Model for Controllable Generation <a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:7" class="footnote-text"><span>Plug and Play Language Models: A Simple Approach to Controlled Text Generation <a href="#fnref:7" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:8" class="footnote-text"><span>CoCon: A Self-Supervised Approach for Controlled Text Generation <a href="#fnref:8" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:9" class="footnote-text"><span>Attribute Alignment: Controlling Text Generation from Pre-trained Language Models <a href="#fnref:9" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:10" class="footnote-text"><span>Learning to Generate Product Reviews from Attributes <a href="#fnref:10" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:11" class="footnote-text"><span>Cyclic consistency based product review generator from attributes <a href="#fnref:11" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:12" class="footnote-text"><span>Retrieval-Augmented Controllable Review Generation <a href="#fnref:12" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:13" class="footnote-text"><span>Towards Automatic Generation of Product Reviews from Aspect-Sentiment Scores <a href="#fnref:13" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:14" class="footnote-text"><span>Aspect-Level Sentiment-Controllable Review Generation with Mutual Learning Framework <a href="#fnref:14" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:15" class="footnote-text"><span>Mutual disentanglement learning for joint fine-grained sentiment classification and controllable text generation <a href="#fnref:15" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:16" class="footnote-text"><span>Hierarchical template transformer for fine-grained sentiment controllable generation <a href="#fnref:16" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vim cheatsheet</title>
    <link href="/vim-cheatsheet/"/>
    <url>/vim-cheatsheet/</url>
    
    <content type="html"><![CDATA[<p>A vim command cheatsheet.</p><span id="more"></span><h3 id="简介">简介</h3><p>Vim是一个免费开源的文本编辑器，是在vi的基础上进化而来。当我们在编程时，大部分时间被用来读/更改代码，而非写。针对此，Vim被设计成了一种模态编辑器，它拥有许多种模式，对应于不同的修改文字的需求。</p><p>vim的基本模式有：</p><ul><li>Normal: 在文件中移动，修改</li><li>Insert: 插入文本</li><li>Replace: 更换部分文本</li><li>Visual: 选择一块文字（按字/行/块）</li><li>Command-line: 执行命令</li></ul><p>在不同模式下，不同的键有着不同的涵义。比如，在Normal模式下，按键<code>j</code>意味着向下移动一行，而在Insert模式下，它意味着在光标位置处插入字符j。</p><p>我们可以通过按下<code>&lt;ESC&gt;</code>从任何模式退出，返回到Normal模式。而在Normal模式下，按<code>i</code>即可进入Insert模式，按<code>:</code>即可进入Command-line模式，按<code>R</code>即可进入Replace模式，按<code>v</code>即可进入Visual模式。</p><h3 id="基本操作">基本操作</h3><h4 id="插入文本">1 插入文本</h4><p>按下<code>i</code>进入Insert模式，在光标处插入文本。可利用树表/方向键移动光标</p><h4 id="执行命令">2 执行命令</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cli">:q # 退出当前窗口<br>:w # 保存<br>:wq # 保存并退出<br>:e &lt;filename&gt; # 打开名为filename的文件<br>:ls # 显示在vim中打开的文件<br>:help &lt;command&gt; # 显示命令command的帮助文档<br></code></pre></td></tr></table></figure><h4 id="移动光标">3 移动光标</h4><ul><li>基本：<code>hjkl</code> 左，下，上，有</li><li>单词：<code>w</code>下一个单词的起始处, <code>b</code>当前单词的首字母处, <code>e</code>当前单词的末尾</li><li>行：<code>0</code>行的开始处, <code>^</code>第一个非空白符的字符处, <code>$</code>行的末尾</li><li>屏幕：<code>H</code>屏幕的最高处, <code>M</code>屏幕的中间, <code>L</code>屏幕的最底部</li><li>滚动：<code>^u</code>向上, <code>^d</code>向下</li><li>文件：<code>gg</code>文件的开始, <code>G</code>文件的结束</li><li>行数：<code>&#123;number&#125;&lt;CR&gt;</code>/<code>&#123;number&#125;G</code> 移动到第{number}行</li><li>查找字符：<code>f&#123;char&#125;</code>, <code>t&#123;char&#125;</code>, <code>F&#123;char&#125;</code>, <code>T&#123;char&#125;</code><ul><li>在当前行上 查找/向前查找/向后查找 字符{char}</li></ul></li><li>查找正则表达式：<code>/&#123;regex&#125;</code>, <code>n</code>/<code>N</code>向后/向前移动</li></ul><h4 id="选择">4 选择</h4><ul><li>Visual: <code>v</code></li><li>Visual Line: <code>V</code></li><li>Visual Block: <code>^v</code></li></ul><p>进入visual模式后，可利用移动光标的键移动光标，选择相应的区域</p><h4 id="修改">5 修改</h4><ul><li><code>i</code> 进入Insert模式</li><li><code>o</code>/<code>O</code></li><li><code>d&#123;motion&#125;</code> 删除xx动作对应的内容</li><li><code>c&#123;motion&#125;</code> 修改xx动作对应的内容<ul><li>e.g. <code>cw</code> 是修改当前单词</li><li>等效于 <code>d&#123;motion&#125;</code> + <code>i</code></li></ul></li><li><code>x</code> 删除当前字符 (等效于 <code>dl</code>)</li><li><code>s</code> 替换当前字符(等效于 <code>cl</code>)</li><li><code>u</code> 撤销更改, <code>&lt;C-r&gt;</code> 恢复更改 注：从<code>i</code> 到<code>&lt;ESC&gt;</code>之间的所有动作算一次更改</li><li><code>y</code> 复制</li><li><code>p</code> 粘贴</li><li>…</li></ul><h4 id="计数">6 计数</h4><p>数字a+指令c，执行指令a次</p><ul><li><code>3w</code> 向前移动三个单词</li><li><code>5j</code> 向下移动五行</li><li><code>7dw</code> 删除七个单词</li></ul><h4 id="修饰符">7 修饰符</h4><p><code>i</code> -- 内部， <code>a</code> -- 周围</p><ul><li><code>ci(</code> 改变小括号内的内容</li><li><code>ci[</code> 改变中括号内的内容</li><li><code>da'</code> 删除单引号中的内容，包括双引号</li></ul><section class="footnotes"><h2>参考</h2><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://missing.csail.mit.edu/2020/editors/">missing semester lecture notes</a> <a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://zh.wikipedia.org/wiki/Vim">wikipedia-Vim</a> <a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Cheatsheet</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vim</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git cheatsheet</title>
    <link href="/git_cheatsheet/"/>
    <url>/git_cheatsheet/</url>
    
    <content type="html"><![CDATA[<p>A git command cheatsheet.</p><p><span id="more"></span></p><h4 id="create-repo">1 create repo</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cli">git init<br></code></pre></td></tr></table></figure><p>初始化当前目录为git仓库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cli">git clone &lt;url&gt; <br>git clone &lt;url&gt; &lt;dir&gt; # 将仓库克隆到指定的目录<br></code></pre></td></tr></table></figure><p>从<code>url</code>克隆仓库</p><h4 id="modify-and-commit">2 modify and commit</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cli">git add &lt;filename&gt; # 添加名为filename的文件的变化<br>git add . # 添加当前目录下及其子目录下的所有文件的变化<br></code></pre></td></tr></table></figure><p>添加文件到暂存区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cli">git commit -m &lt;version comment&gt; # 将当前版本提交，并添加注释`&lt;version comment&gt;`<br></code></pre></td></tr></table></figure><p>提交暂存区到仓库。</p>]]></content>
    
    
    <categories>
      
      <category>Cheatsheet</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OS: file system</title>
    <link href="/OS-file-system/"/>
    <url>/OS-file-system/</url>
    
    <content type="html"><![CDATA[<p>此文件系统是基于FUSE架构的EXT2文件系统，可在linux上运行。此文件系统用于为操作系统提供文件在特定存储设备上的组织、访问支持,可管理调度设备的存储空间，并实现了文件从标识到实际地址的映射，文件的控制存取。</p><p>文件系统的总体功能为：挂载(mount)、卸载(unmount)、创建文件/文件夹(touch/mkdir)、查看文件夹下的文件(ls)。</p><p>代码：<a href="https://github.com/Mimasss2/A-Simple-File-System">A Simple file system</a></p><span id="more"></span><h3 id="整体布局">整体布局</h3><figure><img src="/img/OS-file-system/structure.png" alt="文件系统整体布局" /><figcaption aria-hidden="true">文件系统整体布局</figcaption></figure><p>系统主要分为五个部分：</p><ol type="1"><li>超级块：包含系统整体信息。</li><li>索引节点位图：记录所有索引节点的使用情况，1bit对应一个索引节点。</li><li>数据块位图：记录所有数据块的使用情况，1bit对应一个数据块。</li><li>索引节点：记录文件的原数据，和一个文件对应。</li><li>数据块：记录文件的内容。分配时不一定连续分配。</li></ol><h3 id="数据存储结构说明">数据/存储结构说明</h3><p>超级块的内存结构： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_super</span> &#123;</span><br>    <span class="hljs-type">int</span>         driver_fd; <span class="hljs-comment">// 磁盘对应的文件描述符</span><br>    <span class="hljs-type">int</span>         max_ino; <span class="hljs-comment">// 所能容纳的最大文件数量</span><br><br>    <span class="hljs-type">int</span>         sz_io; <span class="hljs-comment">// 与磁盘数据交换的块大小</span><br>    <span class="hljs-type">int</span>         sz_block; <span class="hljs-comment">// 文件系统的块大小</span><br>    <span class="hljs-type">int</span>         sz_disk; <span class="hljs-comment">// 磁盘的容量大小</span><br><br>    <span class="hljs-type">uint8_t</span>     *map_inode; <span class="hljs-comment">// inode位图</span><br>    <span class="hljs-type">uint8_t</span>     *map_data;  <span class="hljs-comment">// data位图</span><br>    <span class="hljs-type">int</span>         map_inode_blks; <span class="hljs-comment">// inode 位图占用的块数</span><br>    <span class="hljs-type">int</span>         map_inode_offset; <span class="hljs-comment">// inode 位图在磁盘上的偏移</span><br><br>    <span class="hljs-type">int</span>         map_data_blks; <span class="hljs-comment">// data 位图占用的块数</span><br>    <span class="hljs-type">int</span>         map_data_offset; <span class="hljs-comment">// data 位图在磁盘上的偏移</span><br><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_dentry</span> *<span class="hljs-title">root_dentry</span>;</span> <span class="hljs-comment">// 根目录dentry</span><br><br>    <span class="hljs-type">int</span> inode_offset; <span class="hljs-comment">// inode块在磁盘上的偏移</span><br>    <span class="hljs-type">int</span> data_offset;  <span class="hljs-comment">// data块在磁盘上的偏移</span><br><br>    <span class="hljs-type">int</span> sz_usage; <span class="hljs-comment">// 已用空间</span><br><br><br>    boolean is_mounted;<br>&#125;;<br><br></code></pre></td></tr></table></figure></p><p>索引项inode的内存结构: <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_inode</span> &#123;</span><br>    <span class="hljs-type">int</span> ino;                <span class="hljs-comment">// 在inode位图中的下标</span><br>    <span class="hljs-type">int</span> size;               <span class="hljs-comment">// 文件已占用空间</span><br>    <span class="hljs-type">int</span> dir_cnt;            <span class="hljs-comment">// 目录项数量</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_dentry</span> *<span class="hljs-title">dentry</span>;</span>  <span class="hljs-comment">// 指向该inode的dentry</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_dentry</span> *<span class="hljs-title">dentrys</span>;</span> <span class="hljs-comment">// 所有目录项</span><br>    <span class="hljs-type">int</span> block_pointer[<span class="hljs-number">6</span>];   <span class="hljs-comment">// 数据块指针</span><br>    <span class="hljs-type">uint8_t</span>* data[<span class="hljs-number">6</span>];       <span class="hljs-comment">// 对应数据块中存储的内容</span><br>    <br>&#125;;<br><br></code></pre></td></tr></table></figure></p><p>目录项dentry的内存结构： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_dentry</span> &#123;</span><br>    <span class="hljs-type">char</span>                fname[MAX_NAME_LEN];<br>    <span class="hljs-type">uint32_t</span>            ino; <span class="hljs-comment">// 在inode位图中的下标</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_inode</span>*   <span class="hljs-title">inode</span>;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_dentry</span>*  <span class="hljs-title">parent</span>;</span>   <br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_dentry</span>*  <span class="hljs-title">brother</span>;</span>                      <br>    FILE_TYPE       ftype; <span class="hljs-comment">// 指向的 ino 文件类型</span><br>    <span class="hljs-type">int</span>             valid; <span class="hljs-comment">// 该目录项是否有效</span><br>&#125;;<br><br></code></pre></td></tr></table></figure></p><p>超级块的磁盘结构： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_super_d</span></span><br><span class="hljs-class">&#123;</span> <br>    <span class="hljs-type">uint32_t</span>    magic_num; <span class="hljs-comment">// 验证磁盘是否已经被挂载的幻数</span><br><br>    <span class="hljs-type">int</span>         max_ino; <span class="hljs-comment">// 最多支持的文件数</span><br><br>    <span class="hljs-type">int</span>         map_inode_blks; <span class="hljs-comment">// inode 位图占用的块数</span><br>    <span class="hljs-type">int</span>         map_inode_offset; <span class="hljs-comment">// inode 位图在磁盘上的偏移</span><br><br>    <span class="hljs-type">int</span>         map_data_blks; <span class="hljs-comment">// data 位图占用的块数</span><br>    <span class="hljs-type">int</span>         map_data_offset; <span class="hljs-comment">// data 位图在磁盘上的偏移</span><br><br>    <span class="hljs-type">int</span>         inode_offset; <span class="hljs-comment">// inode块在磁盘上的偏移</span><br>    <span class="hljs-type">int</span>         data_offset; <span class="hljs-comment">// data块在磁盘上的偏移</span><br><br>    <span class="hljs-type">int</span>         sz_usage; <span class="hljs-comment">// 已用空间</span><br><br>&#125;;<br></code></pre></td></tr></table></figure></p><p>索引项inode的磁盘结构： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_inode_d</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-type">uint32_t</span>    ino;                <span class="hljs-comment">// 在 inode 位图中的下标</span><br>    <span class="hljs-type">int</span>         size;               <span class="hljs-comment">// 文件已占用空间</span><br>    FILE_TYPE   ftype;              <span class="hljs-comment">// 文件类型（目录类型、普通文件类型）</span><br>    <span class="hljs-type">int</span>         dir_cnt;            <span class="hljs-comment">// 如果是目录类型文件，下面有几个目录项</span><br>    <span class="hljs-type">int</span>         block_pointer[<span class="hljs-number">6</span>];   <span class="hljs-comment">// 数据块指针（可固定分配）</span><br>&#125;;<br></code></pre></td></tr></table></figure></p><p>目录项dentry的磁盘结构： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">newfs_dentry_d</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-type">char</span>               fname[SFS_MAX_FILE_NAME];  <span class="hljs-comment">// 文件名</span><br>    FILE_TYPE          ftype;                     <span class="hljs-comment">// 文件格式</span><br>    <span class="hljs-type">int</span>                ino;                       <span class="hljs-comment">// 在inode位图中的下标</span><br>&#125;; <br></code></pre></td></tr></table></figure></p><h3 id="功能点说明">功能点说明</h3><h4 id="mount">mount</h4><ol type="1"><li>将文件系统的全局参数newfs_option作为参数，调用newfs_utils.c中的fs_mount函数，实现文件系统的挂载，其具体执行流程如下。</li><li>fs_mount函数首先调用ddriver_open，打开磁盘文件，并将文件描述符存储到文件系统的超级块中。</li><li>从磁盘中读取磁盘容量，io块大小，数据块大小，并将其存储到超级块中。</li><li>从磁盘的超级块中读取文件系统的超级块信息到超级块的磁盘表示结构中。</li><li>调用new_dentry函数，创建根节点的目录项。</li><li>若磁盘的超级块中的幻数不正确，即磁盘从未被挂载，则根据之前读取到的块大小信息，计算超级块/索引节点位图/数据块位图/索引块/数据块占用的磁盘块数，在磁盘中的位置偏移。将计算的结果存储到超级块的磁盘存储结构/内存存储结构中。</li><li>从磁盘中读取索引节点位图、数据块位图。</li><li>调用fs_alloc_inode函数，为根节点的目录项创建相应的索引节点，并使根节点的目录项指向词索引节点。并将超级块中的根目录指针指向此目录项。</li><li>调用fs_dump_map打印此时的索引节点位图和数据块位图分布。</li></ol><h4 id="unmount">unmount</h4><ol type="1"><li>调用newfs_utils.c中的fs_unmount函数，实现文件系统的卸载，其具体执行流程如下。</li><li>首先判断超级块中的挂载标识符，若文件系统未被挂载，则直接错误返回。</li><li>调用fs_sync_inode函数，从根节点向下刷写节点，将文件和文件夹中的信息写回到磁盘。</li><li>将超级块内存表示中的信息复制到超级块的磁盘表示中，并将超级块的磁盘表示中存储的信息写回磁盘。</li><li>将索引节点位图、数据块位图写回到磁盘中。</li><li>释放内存中索引节点位图、数据块位图占用的内存空间。</li><li>关闭磁盘的文件描述符。</li></ol><h4 id="touch">touch</h4><ol type="1"><li>调用newfs_getattr函数，获取当前目录的属性。</li><li>调用newfs_getattr函数，获取待创建文件的属性（判断文件是否已经存在）。</li><li>若待创建的文件已存在，则跳过创建文件的步骤，等待下一条命令。</li><li>若待创建的文件不存在，则调用newfs_mknod创建文件，newfs_mknod函数执行流程如下。</li><li>调用fs_lookup，解析文件路径，并得到待创建文件的上级目录的目录项。</li><li>如果fs_lookup找到了要创建的文件，即要创建的文件已存在，则错误返回。</li><li>调用fs_get_fname函数，解析文件的文件名（不含上级目录）。</li><li>创建待创建文件的目录项，并将其父目录项指针指向上级目录</li><li>调用fs_alloc_inode函数，为此文件分类索引节点，并使目录项指向索引节点。</li><li>调用fs_alloc_dentry函数，为上级目录创建索引节点，将其存储到内存中。</li><li>调用newfs_getattr函数，获取创建的文件的属性。若属性获取成功，则意味着文件创建成功。</li></ol><h4 id="mkdir">mkdir</h4><ol type="1"><li>调用newfs_getattr函数，获取当前目录的属性。</li><li>调用newfs_getattr函数，获取待创建目录的属性（判断目录是否已经存在）。</li><li><strong>若待创建的目录已存在</strong>，则提示错误信息：目录已存在。</li><li><strong>若目录不存在</strong>，则调用newfs_mkdir创建目录。newfs_mkdir函数执行流程如下。</li><li>调用fs_lookup函数，解析文件路径，并得到上级目录的目录项。</li><li>如果fs_lookup函数找到了要创建的文件夹，即要创建的文件夹已存在，则错误返回。</li><li>如果上级目录的文件属性为文件，则无法再创建下级目录，错误返回。</li><li>调用fs_get_fname函数，解析目录的名字。</li><li>调用new_dentry函数，创建目录的目录项，并将其父目录项指针指向上级目录的目录项</li><li>调用fs_alloc_inode函数，创建此目录的索引节点，并将目录的目录项指向索引节点。</li><li>调用fs_alloc_dentry函数，创建上级目录项对应的索引节点</li><li>调用newfs_getattr函数，获取创建的目录的属性。若属性获取成功，则意味着目录创建成功。</li></ol><h4 id="ls">ls</h4><ol type="1"><li>调用newfs_getattr函数，获取ls命令指定的路径（目录/文件）的属性。</li><li>若指定的路径为文件，则打印文件名。</li><li>若指定的路径为目录，则执行以下步骤。</li><li>依次调用newfs_readdir函数，读取指定目录中的内容，其中参数offset（指示第i个目录项）依次递增，直到所有目录项读取完毕。newfs_readdir的执行流程如步骤6-8所述。</li><li>调用newfs_getattr函数，获取上一步获取的目录项对应的属性值。。</li><li>调用fs_lookup，找到传入路径的目录项。</li><li>如果目录项存在，则找到目录项指向的索引节点，并调用fs_get_dentry函数获取目录中的第offset个目录项。</li><li>若目录项存在，则调用filler函数，把目录项中的内容填充到buf中。</li></ol><h3 id="使用指南">使用指南</h3><h4 id="mount-1">mount:</h4><p><strong>功能</strong>：挂载newfs文件系统</p><p><strong>外部指令</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">fusermount [options] mountpoint<br></code></pre></td></tr></table></figure><p><strong>参数说明</strong>：</p><ul><li>-h 显示帮助文档</li><li>-v 显示版本号</li><li>-o 挂载的选项 opt [,opt…]</li><li>-u 卸载</li><li>-q 不显示部分信息</li><li>-z 强制卸载，尽管资源仍然处于被使用状态</li></ul><h4 id="umount">umount:</h4><p><strong>功能</strong>：卸载newfs文件系统</p><p><strong>使用语法</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">fusermount -u mountpoint<br></code></pre></td></tr></table></figure><p>参考mount中说明的fusermount的相关信息</p><h4 id="mkdir-1">mkdir:</h4><p><strong>功能</strong>：新建目录</p><p><strong>使用语法</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> [-p] dirName<br></code></pre></td></tr></table></figure><p><strong>参数说明</strong>：</p><ul><li>-p 确保目录名称存在，不存在的就建一个。</li></ul><p><strong>实例</strong></p><p>在工作目录下，建立一个名为 dir0的子目录 :</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> dir0<br></code></pre></td></tr></table></figure><p>在工作目录下的 dir0 目录中，建立一个名为 test 的子目录。若 dir0 目录原本不存在，则建立一个。（注：本例若不加 -p 参数，且原本 dir0 目录不存在，则产生错误。）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p dir0/test<br></code></pre></td></tr></table></figure><h4 id="touch-1">touch:</h4><p><strong>功能</strong>：修改文件或者目录的时间属性，包括存取时间和更改时间。若文件不存在，系统会建立一个新的文件。</p><p><strong>使用语法</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">touch</span> [-acfm][-d&lt;日期时间&gt;][-r&lt;参考文件或目录&gt;] [-t&lt;日期时间&gt;][--<span class="hljs-built_in">help</span>][--version][文件或目录…]<br></code></pre></td></tr></table></figure><p><strong>参数说明</strong>：</p><ul><li>-a 改变档案的读取时间记录。</li><li>-m 改变档案的修改时间记录。</li><li>-c 假如目的档案不存在，不会建立新的档案。与 --no-create 的效果一样。</li><li>-f 不使用，是为了与其他 unix 系统的相容性而保留。</li><li>-r 使用参考档的时间记录，与 --file 的效果一样。</li><li>-d 设定时间与日期，可以使用各种不同的格式。</li><li>-t 设定档案的时间记录，格式与 date 指令相同。</li></ul><p><strong>实例</strong></p><p>使用指令"touch"修改文件"testfile"的时间属性为当前系统时间，输入如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">touch</span> testfile                <span class="hljs-comment">#修改文件的时间属性 </span><br></code></pre></td></tr></table></figure><p>首先，使用ls命令查看testfile文件的属性，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">ls</span> -l testfile                <span class="hljs-comment">#查看文件的时间属性   </span><br><span class="hljs-comment">#原来文件的修改时间为16:09  </span><br>-rw-r--r-- 1 hdd hdd 55 2011-08-22 16:09 testfile<br></code></pre></td></tr></table></figure><p>执行指令"touch"修改文件属性以后，并再次查看该文件的时间属性，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">touch</span> testfile                <span class="hljs-comment">#修改文件时间属性为当前系统时间  </span><br>$ <span class="hljs-built_in">ls</span> -l testfile                <span class="hljs-comment">#查看文件的时间属性  </span><br><span class="hljs-comment">#修改后文件的时间属性为当前系统时间  </span><br>-rw-r--r-- 1 hdd hdd 55 2011-08-22 19:53 testfile  <br></code></pre></td></tr></table></figure><p>使用指令"touch"时，如果指定的文件不存在，则将创建一个新的空白文件。例如，在当前目录下，使用该指令创建一个空白文件"file"，输入如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">touch</span> file            <span class="hljs-comment">#创建一个名为“file”的新的空白文件 </span><br></code></pre></td></tr></table></figure><h4 id="ls-1">ls:</h4><p><strong>功能</strong>：显示指定工作目录下之内容（列出目前工作目录所含之文件及子目录)。</p><p><strong>使用语法</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">ls</span> [-alrtAFR] [name...]<br></code></pre></td></tr></table></figure><p><strong>参数</strong> :</p><ul><li>-a 显示所有文件及目录 (. 开头的隐藏文件也会列出)</li><li>-l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出</li><li>-r 将文件以相反次序显示(原定依英文字母次序)</li><li>-t 将文件依建立时间之先后次序列出</li><li>-A 同 -a ，但不列出 "." (目前目录) 及 ".." (父目录)</li><li>-F 在列出的文件名称后加一符号；例如可执行档则加 "*", 目录则加 "/"</li><li>-R 若目录下有文件，则以下之文件亦皆依序列出</li></ul><p><strong>实例</strong> 列出当前目录(.)下的所有目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">ls</span> .<br>dir0  dir1 file0<br></code></pre></td></tr></table></figure><p>列出目前工作目录下所有名称是 s 开头的文件，越新的排越后面 : <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">ls</span> -ltr s*<br></code></pre></td></tr></table></figure></p><p>将 /mnt 目录以下所有目录及文件详细资料列出 : <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">ls</span> -lR /mnt<br></code></pre></td></tr></table></figure></p><p>列出目前工作目录下所有文件及目录；目录于名称后加 "/", 可执行档于名称后加 "*" : <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">ls</span> -AF<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>Projects</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>无监督句子多样性评价指标</title>
    <link href="/NLP_sentence_diversity_evaluation/"/>
    <url>/NLP_sentence_diversity_evaluation/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在项目推进过程中，产生了对生成句子多样性进行评价、筛选的需求。遂调研了部分现有的无监督句子多样性的评价指标，以备参考使用。 <span id="more"></span></p></blockquote><h2 id="bertscore">BERTScore</h2><p>paper: <a href="https://arxiv.org/abs/1904.09675v3">BERTSCORE: EVALUATING TEXT GENERATION WITH BERT</a></p><p><img src="/img/nlp_sentence_diversity/bertscore.png" /></p><p>每个词找另一个句子中和它内积最大的词</p><p><span class="math display">\[R_{BERT} = \frac{1}{|x|} \underset{x_i \in x}{\Sigma} \underset{\hat{x}\in \hat{x}} {max}  x_i^{T} \hat{x_j},\quadP_{BERT} = \frac{1}{\|\hat{x}\|} \underset{\hat{x_i} \in \hat{x}}{\Sigma} \underset{\hat{x} \in \hat{x}}{max} x_i^{T} \hat{x_j}, \quadF_{BERT} = 2\frac{P_{BERT}\cdot R_{BERT}}{P_{BERT} + R_{BERT}}\]</span></p><h4 id="importance-weighting">Importance Weighting</h4><p>based on inverse document frequency</p><p><span class="math display">\[idf(w) = -\log \frac{1}{M} \Sigma_{i=1}^{M} I [w \in x^{(i)}]\]</span></p><h4 id="rescaling">rescaling</h4><p><span class="math display">\[\hat{R}_{BERT} = \frac{R_{BERT} - b}{1-b}\]</span></p><p>b: empirical lower bound, calculated using Common Crawl monolingual datasets</p><h4 id="comparison">Comparison</h4><p>machine translation evalution -&gt; <span class="math inline">\(F_{BERT}\)</span></p><p>text generation in Eglish -&gt; 24-layer <span class="math inline">\(RoBERTa_{large}\)</span></p><p>non-English language -&gt; <span class="math inline">\(BERT_{multi}\)</span></p><h2 id="bleurt">BLEURT</h2><p>paper: <a href="https://arxiv.org/abs/2004.04696">BLEURT: Learning Robust Metrics for Text Generation. ACL 2020</a></p><h4 id="architecture">Architecture</h4><p>Bert + Linear Head</p><h4 id="pre-training-scheme">pre-training scheme</h4><p>random perturbations of Wikipedia sentences augmented with a diverse set of lexical and semantic-level supervision signals</p><ul><li>mask-filling with BERT -&gt; lexical alterations</li><li>backtranslation</li><li>randomly dropping out words -&gt; to recognize void preditions and sentence truncation in NLG systems</li></ul><p>pretraining metrics: weighted sum of previous metrics</p><h3 id="bartscore">BARTScore</h3><p>paper: <a href="https://arxiv.org/abs/2106.11520">BARTSCORE: Evaluating Generated Text as Text Generation</a></p><p>ExplainaBoard：http://explainaboard.nlpedia.ai/leaderboard/task-meval/</p><figure><img src="/img/nlp_sentence_diversity/bart_board.png" alt="image-20221128102518705" /><figcaption aria-hidden="true">image-20221128102518705</figcaption></figure><h4 id="evaluation-perspectives">evaluation perspectives:</h4><ul><li>Informativeness</li><li>Relevance</li><li>Fluency</li><li>Coherence</li><li>FActuality</li><li>Semantic Coverage</li><li>Adequacy</li></ul><h4 id="bartscore-1">BARTScore</h4><p><span class="math display">\[BARTSCORE = \Sigma_{t=1}^{m} \omega_t \log p(y_t | y_{&lt;t}, x, \theta)\]</span></p><p>using prompt to augment metrics</p><p>没太看明白，一开始列了一堆指标，最后又只有一个BARTScore。看了眼ExplainaBoard，猜测可能是评判的任务/输入数据对<span class="math inline">\(\{x,y\}\)</span>不同，BARTScore体现出的评判句子的方面就不一样</p><h2 id="moverscore">MoverScore</h2><p>MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance. <a href="https://arxiv.org/abs/1909.02622">link</a></p><h4 id="moverdistance">MoverDistance</h4><p><span class="math display">\[WMD(x^n, y^n) := \underset{F \in R^{|x^n| \times |y^n|}}{min} &lt;C,F&gt;,\quad s.t. F1 = f_{x^n}, F^T 1 = f_{y^n}\]</span></p><p><span class="math inline">\(C_{ij} = d(x_i^n, y_j^n)\)</span>, the distance between the i-th n-gram of x and the j-th n-gram of y</p><p><span class="math inline">\(F\)</span>: transportation flow matrix, <span class="math inline">\(F_{ij}\)</span> denoting the amount of flow traveling from the ith n-gram <span class="math inline">\(x_i^n\)</span> in <span class="math inline">\(x^n\)</span> to the j-th n-gram <span class="math inline">\(y_j^n\)</span> in <span class="math inline">\(y^n\)</span>.</p><p><span class="math inline">\(&lt;C,F&gt; = sum(C \odot F)\)</span></p><p><span class="math inline">\(d(x_i^n, y_j^n)\)</span> Euclidean distance</p><p><span class="math inline">\(f_{x^n_i} = \frac{1}{Z} \Sigma_{k=i}^{i+n-1} idf(x_k)\)</span></p><h4 id="vs-bertscore">vs BERTScore</h4><figure><img src="/img/nlp_sentence_diversity/bartscore_vs_bertscore.png" alt="image-20221128093223272" /><figcaption aria-hidden="true">image-20221128093223272</figcaption></figure><p>对于某个词，BERTScore算原句子中与它最相似的词的相似度（内积），而MoverScore算这个词和所有其他词的加权内积和，权重（即公式中的<span class="math inline">\(F\)</span>）通过idx算</p><h2 id="embedding-average">Embedding Average</h2><p>直接计算生成文本和参考文本中词向量的平均值作为文本的向量表示，然后计算两个文本的余弦相似度作为生成文本和参考文本的相似度：</p><p><span class="math display">\[\bar{e_r} = \frac{\Sigma_{\omega \in r} e_{\omega}}{| \Sigma_{\omega &#39; \in r} e_{\omega &#39;}|}\]</span> <span class="math display">\[EA := cos(\bar{e_r}, \bar{e_{\hat{r}}})\]</span></p><h2 id="perplexity">Perplexity</h2><h2 id="p.s.">p.s.</h2><p>很多现有的评价生成的文本的指标是基于Machine Translation任务的，计算原句子和翻译句子的相似度/匹配度。</p><h5 id="评价句子相似度的一些指标">评价句子相似度的一些指标</h5><ul><li><a href="https://aclanthology.org/S17-2001/">Semantic Textual Similarity</a></li><li><a href="https://aclanthology.org/W17-4767/">MEANT 2.0</a></li><li><a href="https://arxiv.org/abs/2109.06379">Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation</a></li><li>…</li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Simple Compiler</title>
    <link href="/A-Simple-Compiler/"/>
    <url>/A-Simple-Compiler/</url>
    
    <content type="html"><![CDATA[<p>一个 Java 实现的 TXT 语言编译器, 目标平台为 RISC-V 32 (指令集 RV32M)。编译器大致分为词法分析、语法分析、语义分析及中间代码生成、目标代码生成四个部分。</p><span id="more"></span><p>代码：<a href="https://github.com/Mimasss2/A-Simple-Compiler">A Simple Compiler</a></p><h3 id="源语言的示例代码">源语言的示例代码</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">int</span> result;<br><span class="hljs-type">int</span> a;<br><span class="hljs-type">int</span> b;<br><span class="hljs-type">int</span> c;<br>a = <span class="hljs-number">8</span>;<br>b = <span class="hljs-number">5</span>;<br>c = <span class="hljs-number">3</span> - a;<br>result = a * b - ( <span class="hljs-number">3</span> + b ) * ( c - a );<br><span class="hljs-keyword">return</span> result;<br></code></pre></td></tr></table></figure><h2 id="词法分析">词法分析</h2><h3 id="编码表">编码表</h3><table><thead><tr class="header"><th>类别</th><th>正则表达式</th></tr></thead><tbody><tr class="odd"><td>return</td><td>return</td></tr><tr class="even"><td>=</td><td>=</td></tr><tr class="odd"><td>,</td><td>,</td></tr><tr class="even"><td>Semicolon</td><td>;</td></tr><tr class="odd"><td>+</td><td>+</td></tr><tr class="even"><td>-</td><td>-</td></tr><tr class="odd"><td>*</td><td>*</td></tr><tr class="even"><td>/</td><td>/</td></tr><tr class="odd"><td>(</td><td>(</td></tr><tr class="even"><td>)</td><td>)</td></tr><tr class="odd"><td>id</td><td>[a-zA-Z_][a-zA-Z]*</td></tr><tr class="even"><td>IntConst</td><td>[0-9]+</td></tr></tbody></table><h3 id="正则文法">正则文法</h3><p><span class="math inline">\(G=(V,T,P,S)\)</span>，其中<span class="math inline">\(V=\{S, A, B, C, 0,1,2,…,9, char\}\)</span>,<span class="math inline">\(T=\{任意符号\}\)</span>，<span class="math inline">\(P\)</span>定义如下</p><p>约定： <span class="math inline">\([s-t]\)</span>表示从s到t的所有ASCII字符中的一个</p><p>标识符：<span class="math inline">\(S \rightarrow [a-z] A,\)</span> <span class="math inline">\(A \rightarrow [a-z] A | [0-9] A | ϵ\)</span></p><p>整常数：<span class="math inline">\(S \rightarrow [1-9] B,\)</span> <span class="math inline">\(B \rightarrow [0-9] B | ϵ\)</span></p><p>运算符：<span class="math inline">\(S \rightarrow C,\)</span> <span class="math inline">\(C \rightarrow = | * | + | - | /\)</span></p><p>分隔符：<span class="math inline">\(S \rightarrow D,\)</span> <span class="math inline">\(D \rightarrow ; | ( | ) | ,\)</span></p><h3 id="状态转换图">状态转换图</h3><p>根据识别的编码不同，将状态机划分为不同的状态，共计14个状态。在每识别到终止状态时，调用相关的函数，将语法单元添加到维护的表格中，并重新回到起始状态。状态机DFA对应的状态转换图如下图所示。</p><figure><img src="/img/A-Simple-Compiler/状态转换图.png" alt="状态转换图" /><figcaption aria-hidden="true">状态转换图</figcaption></figure><h3 id="流程">流程</h3><p>使用列表存储每个识别出的语法单元，读入输入代码，从前往后逐个读取字符，若遇到空格等其他空白字符跳过，否则，按照状态转换图识别语法单元，将其加入token列表中。若此语法单元为单词，且不是标识符，且不在符号表中，则其为新识别出的变量，将其添加到符号表中。</p><h2 id="语法分析">语法分析</h2><h3 id="状态栈和符号栈的数据结构">状态栈和符号栈的数据结构</h3><p>使用Stack类作为状态栈和符号栈的数据结构，状态栈的元素的基类为Status类，符号栈的基类为Token类（后续发现实际分析过程中不需要用到符号栈）。通过peek()函数获取栈顶元素，通过push()函数向栈中压入元素，通过pop()函数弹出栈顶元素，通过empty()函数判断栈是否为空。</p><h3 id="流程-1">流程</h3><ol type="1"><li>向状态栈中压入初始状态，向符号栈中压入符号“$”。</li><li>依次遍历输入串中的字符，根据当前状态栈栈顶的状态，判断此时应执行的Action。</li><li>若执行的动作为移进，则根据LR1分析表获取要转移到的状态（程序中存储在action对应的Status对象中），将状态压入状态栈，将字符压入符号栈,并调用移入时对应的观察者的函数（callWhenInShift函数）,通知观察者当前读到的字符和要转移到的状态。</li><li>若执行的动作为规约，则根据LR1分析表获取要规约的产生式（程序中存储在action对象的production属性中），调用规约时对应的观察者的函数（callWhenInReduce函数），通知观察者当前读到的字符和要用于规约的产生式，ProductionCollector观察者会将所有规约的产生式依次存储在列表中；获取产生式的头和体，将产生式的体对应的符号数从状态栈和符号栈中弹出，并将产生式的头压入符号栈。根据当前状态和状态站顶部状态查找LR1表，判断此时需要压入状态栈顶部的状态，并将其压入。</li><li>若执行的动作为接受，则调用处于接受状态时对应的观察者的函数（callWhenInAccept）通知各个观察者，语法分析结束。</li><li>重复执行2-5步，直到读完代码中的所有字符，或状态栈为空，或产生错误。</li></ol><h2 id="语义分析和中间代码生成">语义分析和中间代码生成</h2><h3 id="翻译方案">翻译方案</h3><p><span class="math display">\[ S \rightarrow D \  id; \{ id.type = D.type \} \]</span></p><p><span class="math display">\[ D \rightarrow int ; \{ int.type = INT, D.type = int.type \} \]</span></p><p>其余产生式规约式不执行任何动作</p><h3 id="使用的数据结构">使用的数据结构</h3><p><strong>语义分析：</strong>使用基类位SourceCodeType的栈（Stack）作为类型栈typeStack的数据结构，存储当前符号栈内对应符号的类型（type）；使用基类为Token的栈（Stack）作为符号栈tokenStack的数据结构，存储移进的单词（token）</p><p><strong>中间代码生成：</strong>使用基类为Instruction的列表(List)instructions作为中间代码存储的数据结构，依次存储生成的中间代码，使用基类为IRValue的栈（Stack）作为符号栈irValueStack的数据结构，存储符号栈对应的ir表达式的值。</p><h3 id="流程-2">流程</h3><ol type="1"><li>当动作为接受时，不执行任何操作。</li><li>当动作为移进时，将对应的符号压入符号栈。如果此符号为关键字int，则将INT压入类型栈，否则将null压入类型栈。</li><li>当动作为规约时，首先判断要执行规约的产生式编号，若编号为4，则跳到第4步，若编号为5，则跳到第5步，否则，调到第6步.</li><li>此时待规约的产生式为 <span class="math inline">\(S \rightarrow D \ id;\)</span>。分别弹出并获取符号栈和类型栈顶端的两个元素，并设置为符号栈第一个元素（id）在符号表中的类型为类型栈从上往下第二个元素的类型（D对应的类型）。并向符号栈和类型栈中压入null（对应左部的S）。</li><li>此时待规约的产生式为 <span class="math inline">\(D \rightarrow \ int ;\)</span> 弹出符号栈和类型栈栈顶的元素，将类型栈栈顶元素的类型作为左部符号的类型，再压入符号栈，向符号栈中压入null(对应左部的D)。</li><li>此时待规约的产生式没有特殊的翻译动作，只需从符号栈和类型栈中弹出与产生式右部元素个数一致的元素，并压入null作为左部对应的符号/类型。</li></ol><h2 id="目标代码生成">目标代码生成</h2><h3 id="对中间代码进行预处理">对中间代码进行预处理</h3><ol type="1"><li>将操作两个立即数的 BinaryOp 直接进行求值得到结果, 然后替换成 MOV 指令。</li><li>将操作一个立即数的指令 (除了乘法和左立即数减法) 进行调整, 使之满足 a := b op imm 的格式。</li><li>将操作一个立即数的乘法和左立即数减法调整, 前插一条 MOV a, imm, 用 a 替换原立即数, 将指令调整为无立即数指令.</li><li>舍弃Ret指令之后的所有指令</li></ol><h3 id="识别各变量最后一次使用的位置">识别各变量最后一次使用的位置</h3><p>从后往前遍历预处理后的中间代码序列。用列表存储当前已经遍历到过的变量。每处理一条指令，分别判断它的两个原操作数中是否为立即数，若不是，再查看此变量是否被遍历到过。若此变量从未被遍历到过，说明此变量最后一次出现的位置便为这条指令，将此信息存入列表中保存。</p><p>在遍历过程中，若变量出现在指令的目标操作数位置，且不出现在源操作数中，说明此指令前此变量的值与后续执行过程无关，将此变量从存储但钱已经遍历到过的变量列表中删去。</p><h3 id="将中间代码转化为目标代码">将中间代码转化为目标代码</h3><p>创建AsmInstruction类，表示riscv形式的汇编代码类，创建AsmInstructionKind枚举类，表示riscv代码的各种类型。</p><p>创建RegisterAssigner类，用于分配和回收空闲的寄存器。其中，通过列表维护空闲寄存器，利用双射Map维护变量和已利用的寄存器之间的双射关系。当请求分配寄存器时，从空闲寄存器列表随机分配一个寄存器，并将其添加到双射Map中。当回收某一寄存器时，将其从双射Map中删除，并将相应寄存器重新存放回空闲寄存器列表。 遍历处理后的中间代码，提取每条指令的左右操作数，将其转化为相应的AsmInstruction对象，并存放到列表中。</p><p>根据维护的变量最后一次出现的位置信息，若当前指令为变量最后一次出现的指令，则将相应变量对应的寄存器释放。</p>]]></content>
    
    
    <categories>
      
      <category>Projects</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Compiler</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Housing Price estimator</title>
    <link href="/Housing-Price-estimator/"/>
    <url>/Housing-Price-estimator/</url>
    
    <content type="html"><![CDATA[<p>本项目旨在通过房屋交易市场交易记录，挖掘数据间潜在的关联关系，设计高效、解释性强、鲁棒的算法对房屋交易价格进行预测。</p><span id="more"></span><p>代码和数据: https://github.com/Mimasss2/Housing-price-estimator</p><h3 id="可视化工具">可视化工具</h3><ul><li>sweetviz: Python开源库，快速可视化目标值和比较数据集。</li><li>shap: SHapley Additive exPlanation，解释模型输出。</li></ul><h3 id="基本内容">基本内容</h3><h4 id="数据分析">数据分析</h4><p>房屋交易市场交易记录中，包括数值型属性，文字属性，时间属性等。其中数值型属性包括连续值、离散值、缺失值等。文字型属性包括级别、地址、街区等。</p><p>先使用pandas、matplotlib、seaborn，sweetviz等库函数可视化数据，挖掘数据之间的潜在的关系，并去除相关性较小的特征。</p><p>数据清洗前，各特征之间的相关性较弱，相关系数比较低，如下图所示。其中，出售价格是我们的预测目标，和此特征最相关的特征为总平方英尺，但其相关系数仅为<strong>0.43</strong></p><figure><img src="\img\Housing-Price-estimator\数据清洗前特征之间的相关关系.png" alt="数据清洗前特征之间的相关关系" /><figcaption aria-hidden="true">数据清洗前特征之间的相关关系</figcaption></figure><h4 id="数据预处理">数据预处理</h4><p>对选取的特征中的值进行预处理：填充缺失值，将文字属性数值化，识别并处理异常值等。</p><p>用众数填充总单元、居住单元、邮编、修建年份、公寓号中的缺失值。按居住单元分组，用均值填充总平方英尺中的缺失值。用0填充出售价格中的缺失值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 缺失值处理</span><br>train_df = train_df.replace([<span class="hljs-string">&#x27; -  &#x27;</span>, <span class="hljs-string">&#x27;0&#x27;</span>, <span class="hljs-number">0</span>, np.nan], np.nan)<br><br>train_df[<span class="hljs-string">&#x27;总单元&#x27;</span>] = train_df[<span class="hljs-string">&#x27;总单元&#x27;</span>].fillna(train_df[<span class="hljs-string">&#x27;总单元&#x27;</span>].mode()[<span class="hljs-number">0</span>])<br>train_df[<span class="hljs-string">&#x27;居住单元&#x27;</span>] = train_df[<span class="hljs-string">&#x27;居住单元&#x27;</span>].fillna(train_df[<span class="hljs-string">&#x27;居住单元&#x27;</span>].mode()[<span class="hljs-number">0</span>])<br>train_df[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>] = train_df[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>].astype(<span class="hljs-string">&#x27;float64&#x27;</span>)<br>train_df[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>] = train_df[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>].fillna(<br>    train_df.groupby(<span class="hljs-string">&#x27;居住单元&#x27;</span>)[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>].transform(<span class="hljs-string">&#x27;mean&#x27;</span>))<br>train_df[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>] = train_df[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>].fillna(train_df[<span class="hljs-string">&#x27;总平方英尺&#x27;</span>].mode()[<span class="hljs-number">0</span>])<br>train_df[<span class="hljs-string">&#x27;邮编&#x27;</span>] = train_df[<span class="hljs-string">&#x27;邮编&#x27;</span>].astype(<span class="hljs-string">&#x27;float64&#x27;</span>)<br>train_df[<span class="hljs-string">&#x27;邮编&#x27;</span>] = train_df[<span class="hljs-string">&#x27;邮编&#x27;</span>].fillna(train_df[<span class="hljs-string">&#x27;邮编&#x27;</span>].mode()[<span class="hljs-number">0</span>])<br>train_df[<span class="hljs-string">&#x27;修建年份&#x27;</span>] = train_df[<span class="hljs-string">&#x27;修建年份&#x27;</span>].astype(<span class="hljs-string">&#x27;float64&#x27;</span>)<br>train_df[<span class="hljs-string">&#x27;修建年份&#x27;</span>] = train_df[<span class="hljs-string">&#x27;修建年份&#x27;</span>].fillna(train_df[<span class="hljs-string">&#x27;修建年份&#x27;</span>].mode()[<span class="hljs-number">0</span>])<br>train_df[<span class="hljs-string">&#x27;出售价格&#x27;</span>] = train_df[<span class="hljs-string">&#x27;出售价格&#x27;</span>].astype(<span class="hljs-string">&#x27;float64&#x27;</span>)<br>train_df[<span class="hljs-string">&#x27;出售价格&#x27;</span>] = train_df[<span class="hljs-string">&#x27;出售价格&#x27;</span>].fillna(<span class="hljs-number">0</span>)<br>train_df[<span class="hljs-string">&#x27;公寓号&#x27;</span>] = train_df[<span class="hljs-string">&#x27;公寓号&#x27;</span>].fillna(train_df[<span class="hljs-string">&#x27;公寓号&#x27;</span>].mode()[<span class="hljs-number">0</span>])<br>train_df = train_df.drop(train_df[train_df[<span class="hljs-string">&#x27;出售价格&#x27;</span>] == <span class="hljs-number">0</span>].index)<br>train_df = train_df.reset_index()<br></code></pre></td></tr></table></figure><p>去除训练集中出售价格为0的数据。根据图像显示的数据间的关系，以及数据间的相关系数，发现商业单元、土地平方英尺、地役权、出售日期这四个特征与目标出售价格之间的相关性很低，遂将其删除。用均值填充所有含nan的数值列。</p><p>对所有特征进行归一化，并使用主成分分析方法，分析每个特征对总体的贡献。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">target_encoding</span>(<span class="hljs-params">self,target_feature, df, cat_cols, te_cols</span>):<br>      <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(cat_cols) == <span class="hljs-number">0</span>:<br>          <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;All features are encoded&#x27;</span><br>      target_std = df[target_feature].std()<br>      <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> cat_cols:<br>          encoded_std = df.groupby(col)[target_feature].mean().std()<br>          <span class="hljs-keyword">if</span> target_std &lt; encoded_std:<br>              df[col] = df.groupby(col)[target_feature].transform(<span class="hljs-string">&#x27;mean&#x27;</span>)<br>              cat_cols.remove(col)<br>              te_cols.append(col)<br></code></pre></td></tr></table></figure><p>经过多轮缺失值填充，归一化等操作，数据清洗后特征之间的相关关系如下图所示。地役权和所属区域、建筑类型、税收级别关系较强，其他指标间的相关性也略有提升。但出售价格和这些特征之间的相关性还是不太强，这是受到了原始数据复杂性的约束所致。</p><figure><img src="\img\Housing-Price-estimator\数据清洗后特征之间的相关关系.png" alt="数据清洗后特征之间的相关关系" /><figcaption aria-hidden="true">数据清洗后特征之间的相关关系</figcaption></figure><h4 id="模型选择">模型选择</h4><p>首先在普通的LinearRegression线性回归模型上进行预测，再引入带惩罚项函数的模型，如Ridge,Lasso等，进一步采用RandomForest，比较不同模型的回归结果，选择最优模型。</p><h4 id="模型验证">模型验证</h4><p>随机选取原训练集的20%作为验证集，剩下的80%作为训练集。使用训练集对模型进行训练，预测验证集的结果，与实际结果比较，计算损失(均方误差)，评判模型的效果。</p><p>采用shap包可视化各特征对最终结果的影响。其中，总平方英尺和土地平方英尺这两个指标贡献最大。这个结果可以比较直观的理解为，房屋的出售价格和房屋的面积之间的正相关关系较强。在区域相同的情况下，此现象与生活中的场景较为吻合。</p><figure><img src="\img\Housing-Price-estimator\shap可视化各特征对最终结果的影响.png" alt="shap可视化各特征对最终结果的影响" /><figcaption aria-hidden="true">shap可视化各特征对最终结果的影响</figcaption></figure><h3 id="结果分析">结果分析</h3><p>初始时，将所有特征按照常识进行预处理，所得预测结果较差。进一步分析发现处理后的数据与最终结果之间的相关性均较小，最大不超过0.5，而普遍小于0.1。此后利用图像分析各个特征之间的相关性，发现总平方英寸这一特征与目标之间的相关性最高，于是先从此特征入手。利用此单一特征进行回归预测，在测试集上的均方误差为7749025.804。</p><p>此后，加入其他特征，并分组填充缺失值，提高数据质量，使用主成分分析等方法分析特征的重要性，并选取几个比较显著的特征，在测试集上的均方误差为7224550.11</p><p>使用主成分分析对结果进行分析，不同特征对结果均有一定贡献，第一主成分的贡献不到30%。累计解释占比随着特征数的增加而升高，趋势从陡峭趋向平缓。</p><figure><img src="\img\Housing-Price-estimator\主成分分析各特征的解释方差和累计解释占比.png" style="zoom:50%;" /><figcaption aria-hidden="true">主成分分析各特征的解释方差和累计解释占比</figcaption></figure><p>由于此数据集较为复杂，特征之间的相关性较低，难以在任务上得到比较理想的结果，预测价格与实际价格的相关系数最高不超过50%。如果需要更为准测的预测，可能需要更多高质量的相关性较高的数据。</p>]]></content>
    
    
    <categories>
      
      <category>Projects</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>NSCSCC2022 龙芯杯参赛总结</title>
    <link href="/%E9%BE%99%E8%8A%AF%E6%9D%AF%E5%8F%82%E8%B5%9B%E6%80%BB%E7%BB%93/"/>
    <url>/%E9%BE%99%E8%8A%AF%E6%9D%AF%E5%8F%82%E8%B5%9B%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<div class="note note-info">            <p>我参加的是2022年龙芯杯个人赛，从2022年2月左右开始准备，到2022年8月完赛。以下为我的参赛历程与感想。</p>          </div><span id="more"></span><h3 id="赛事简介">赛事简介</h3><p>全称 ： “龙芯杯”全国大学生计算机系统能力培养大赛</p><p>全国大学生计算机系统能力大赛（National Student Computer System Capability Challenge, NSCSCC）是由教育部高等学校计算机类专业教学指导委员会和系统能力培养研究专家组共同发起，以学科竞赛推动专业建设和计算机领域创新人才培养体系改革、培育我国高端芯片及核心系统的技术突破与产业化后备人才为目标,面向高校大学生举办的全国性大赛。</p><p>大赛共分3个赛道：CPU、编译系统、操作系统。其中，CPU赛道即“龙芯杯”竞赛。</p><p>“龙芯杯”竞赛分3个赛道：MIPS团队赛、MIPS个人赛 和 LoongArch挑战赛。</p><ul><li><p>MIPS团队赛 ： 开发支持32位MIPS基准指令集的简易计算机系统。加分项：运行操作系统、实现加速器、设计可演示的应用</p></li><li><p>MIPS个人赛 ： 开发支持32位MIPS基准指令集的简易计算机系统。完成三级功能测试（最多22条指令），支持SRAM、UART，运行监控程序。 总成绩 = 功能测试 得分 + 性能测试 得分</p></li><li><p>LoongArch挑战赛 ： 开发支持LoongArch32 Reduced指令集的简易计算机系统，并在自己编写的CPU上启动Linux操作系统。 总成绩 = 70% * benchmark基准测试成绩 + 30% * 系统展示及答辩</p></li></ul><p>*详细内容可参考<a href="https://github.com/loongson-education/nscscc-wiki">龙芯官方wiki</a></p><h3 id="个人赛要做什么">个人赛要做什么？</h3><ul><li>一个支持MIPS基准指令集的MIPS位系统</li><li>使用实验板上的SRAM作为存储</li><li>CPU核能够通过接口与各I/O设备互联通信</li><li>支持MIPS-C3指令集（总共39条指令左右），运行提供的MIPS监控程序</li><li>决赛：使用汇编语言现场写算法题，编译后放到自己做的CPU上跑</li><li>......</li></ul><h3 id="前期准备">前期准备</h3><p>2022NSCSCC的时间线如下，仅供参考。 <img src="/img/龙芯杯参赛总结/2022timeline.png" /></p><div class="note note-secondary">            <p>我们学校组织备赛开始得较早，在2021年12月底即组织了宣讲和预报名，年后即开始了每周进度汇报会。虽然前期的进度不算快，但每周前进一小步，还是积累了不少东西</p>          </div><p>理论部分，首先阅读《计算机组成与设计》学习设计相关的理论知识，之后跟着雷思磊的《自己动手写cpu》实现一个支持基本的mips指令的cpu。我一开始把书上写的都实现了一遍，之后再看着官方要求的指令把不相关的删掉了，实际上可以只实现需要的部分。</p><p>具体针对比赛所需，我阅读了龙芯官方发的前几届参赛选手的经验指南，但很多写得很长，讲了很多专业术语，最开始看的时候晕头转向的。后来还是先根据官方的技术指南，先明确需求，需要实现什么，再针对性得根据这些看还需要实现什么，在哪些部分可以提高性能。</p><h3 id="系统总体结构">系统总体结构</h3><p>微系统由cpu核心，SRAM控制器，UART控制器三大部分组成，如下图所示。SRAM内存作为存储元件，存储指令和数据，并通过SRAM控制器的接口与cpu核心交换数据。UART串口作为异步通信接口，是CPU与电脑进行通信的控制器/桥梁，cpu核心通过内置的UART控制器实现异步通信。</p><figure><img src="\img\龙芯杯参赛总结\cpu整体架构.png" style="zoom:50%;" /><figcaption aria-hidden="true">cpu总体架构</figcaption></figure><p>cpu核心采用顺序单发射五级流水线，各流水线模块关系如下图所示。五个模块分为取指、译码、运算、访存、回写。其中取指和访存阶段都由可能访问SRAM存储器。另设控制模块，在发生数据冲突时，使流水线停顿，避免结果异常。</p><figure><img src="\img\龙芯杯参赛总结\cpu核心架构.png" style="zoom:75%;" /><figcaption aria-hidden="true">cpu核心架构</figcaption></figure><h3 id="技术栈">技术栈</h3><h4 id="顺序单发射五级流水cpu">顺序单发射五级流水cpu</h4><p>流水线分为取指、解码、运算、访存、回写五个阶段。</p><ul><li>取指：缓存当前指令地址，并从指令存储器中取回指令。</li><li>解码：分段将指令切分、解码，提取操作数、立即数、操作码、寄存器编号等。获取寄存器的值。</li><li>运算：执行各种算术运算，并根据实际执行的运算类型选择结果。</li><li>访存：访问RAM，读写数据。串口的读写等效于特殊地址的内存读写。</li><li>回写：将指令执行的最终结果写回寄存器堆中对应的寄存器中。</li></ul><p>同时，由于乘法运算布线较长，造成频率提升的瓶颈，而涉及乘法运算的指令均不涉及访存。于是，将乘法运算单独提取出来成为一个模块，与运算模块+访存模块并行。</p><h4 id="uart串口通信">uart串口通信</h4><p>通用异步收发器 UART（Universal Asynchronous Receiver/Transmitter)，是一种串行、异步、全双工的通信协议，将所需传输的数据一位接一位地传输，在UART通讯协议中信号线上的状态位高电平代表’1’，低电平代表’0’。其特点是通信线路简单，只要一对传输线就可以实现双向通信，大大降低了成本，但传送速度较慢。</p><p>其中，串口传输的波特率可根据CPU核心的频率做相应的调整。数据流由10个数据位组成：1位起始位，8位有效数据位，1位停止位。</p><p>发送和接受模块的设计参考<a href="https://www.fpga4fun.com/SerialInterface.html">此教程</a></p><h4 id="sram存储">sram存储</h4><p>采用官方提供的FPGA开发板上的SRAM存储器作为存储，指令和数据分开存储，均采用单周期访问。除了访存/取指部分同时访问指令存储器之外，其他情况均不会因访存而产生停顿。</p><p>虽然SRAM官方指南指定的访存所需的最大时间为12ns，即每个访存阶段（时长为一个CPU周期）的时长至少为12ns，这意味着在理论上，这种设计对应的CPU的最大主频可达83.3MHz。但在实际尝试中，由于FPGA开发板布局布线等因素，CPU的主频在60+时已经会产生访存乱码的现象。因此我设计的CPU的主频最高仅达<strong>63.34MHz</strong>，同校的不少个人赛的同学，在这个限制下，频率也只有60+MHz。</p><p>值得一提的是，在优化阶段我曾尝试多周期访存+cache，但仔细分析后发现，这种配置下如果要达到和单周期五级流水相似的性能，需要至少110+M的频率，且多周期访存产生的停顿意味着需要改变延迟槽判断的方式等等一系列细节逻辑的修改，80+M时就会因数据前递的较长连线而产生关键路径。最后权衡系统性能，系统复杂度（稳定度），以及时间分配（练习汇编算法），还是采用了单周期访存、无cache的访存方法。</p><h4 id="基于华莱士树的乘法器">基于华莱士树的乘法器。</h4><p>本CPU采用华莱士树实现两周期乘法器，大大减少了乘法模块的资源消耗，并减少了因dsp乘法连线过长导致的关键路径。华莱士树的简单思想为：将乘法转化为许多个加数求和，每3个加数分为一组，压缩至2个加数，循环往复。</p><p><img src="/img/龙芯杯参赛总结/Wallace-tree-adder.png" /></p><p>根据上图。乘法可转化为乘数的每一位与被乘数相乘，末端添0，相加。此时加法项的个数与乘数的位数相等。华莱士树将每三个分为一组，相加，保存和&amp;进位（两个加数，对应图中每个CSA向下延申的两条线）。再把得到的结果作为新的加数，循环往复执行加法操作，得到最终结果（第6层）。</p><h3 id="参赛作品亮点">参赛作品亮点</h3><p>采用wallace tree实现两周期乘法器，大大减少了乘法模块的资源消耗，并减少了因dsp乘法连线过长导致的关键路径。</p><p>单周期访问sram，在频率较低时极大得减少了因访存而导致的流水线停顿，大大提高了系统的ipc。</p><p>系统运行流畅，停顿概率很低，仅在乘法后RAW-1，访存取指同时访问imem两种情况下才会停顿。</p><h3 id="参赛最终结果">参赛最终结果</h3><p>比赛要求任务全部完成，实现了MIPS C3指令集总共39条指令，支持uart串口通信，sram访存。</p><p>性能测试结果为:</p><ul><li>STREAM：用时0.099s</li><li>MATRIX：用时0.141s</li><li>CRYPTONIGHT:用时0.364s</li></ul><p>总计0.604s。</p><p>决赛时在规定时间内完成了二分查找的汇编算法，并在自己设计的cpu上跑通。</p><p>获奖情况：</p><p><img src="\img\龙芯杯参赛总结\award.jpg" style="zoom:30%;" /></p><h3 id="备赛经验及建议">备赛经验及建议</h3><p><strong>备赛前期：</strong>阅读《计算机组成与设计》，《计算机体系结构：量化研究方法》两本经典书籍学习所需的基本原理。阅读《自己动手写cpu》，并上手写代码，实现一个基本版的cpu。</p><p><strong>备赛冲刺阶段：</strong>可以在初赛前一个半月左右着手开始优化系统，不建议把战线拉太长，不然中间阶段不知道做什么/迷失方向没人讨论的时候会很痛苦。优化前先仔细调研优化方法，及其在比赛任务上的优化效率。可以参考GitHub上之前参赛选手开源出的作品代码作为参考。不用各种优化方法兼顾，重点攻克对于评分任务提升较大，稳定性较高的方案。</p><p><strong>备赛后期：</strong>初赛结束后还有两周左右的时间到决赛，不建议再修改cpu设计，因为时间很匆忙，不一定赶得出来一个稳定版，而且决赛任务不仅仅看重cpu性能。建议放松一两天后着力准备决赛的编程任务。决赛编程任务属于中等难度的算法题，但需要用汇编实现。参考准备路线：跟着<a href="https://github.com/changgyhub/leetcode_101">LeetCode 101</a> 这本算法书练习经典算法。 到c++容器那章前基本就够了，练习的编程语言任意，顺手就好，用高级语言就行，方便在leetcode上在线评测。之后可以再看看University of Alberta 的CMPUT229这门课的<a href="https://github.com/cmput229/MIPSPatterns">MIPS汇编教程</a> , 掌握高级语言流程结构和汇编语言转换的基本方法，用MIPS汇编实现几个经典的算法，如快排，二分等等，并在Mars和自己的cpu上依次验证。</p><p><strong>决赛技巧：</strong>个人赛决赛仍然采用线上测评平台，由于比赛时间有限，同时在线人数较多，决赛时线上编译速度很慢，工程文件改动后重新编译至少需要20-30min，运行测试也需要排队5min左右。但仅仅修改汇编代码只会重新编译汇编代码，工程文件不再重新编译，只需1分钟左右就可在gitlab上编译完成，。因此强烈建议在决赛时不要修改内核，节省时间。同时，可以在决赛前在多个git分支上准备好多个不同频率的工程版本（比如60M稳定版用于测试汇编代码正确性，频率再高的版本用来降低时间刷分），汇编程序写好后可以分别写到这些分支上，就可以在短时间内得到多个在线编译通过的不同频率的提交文件，能够高效刷分测试。（我决赛时只准备了稳定版本的，后面时间比较紧张就没有再提高频率，有点遗憾。）</p><p>最后，十分感谢老师们给我们提供的良好的交流机会，督促我们不断优化性能，为我们提供了优越的备赛交流环境。也非常感谢一同参加比赛的各位大佬十分耐心回答我的问题以及在交流碰撞出的新思路！</p>]]></content>
    
    
    <categories>
      
      <category>Projects</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NSCSCC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HITSZOJ数据结构课程实验平台</title>
    <link href="/HITSZOJ%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%B9%B3%E5%8F%B0/"/>
    <url>/HITSZOJ%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%B9%B3%E5%8F%B0/</url>
    
    <content type="html"><![CDATA[<p>数据结构实验平台，采用沙箱后端运行代码，实现安全的实时评测（OJ）。此平台搭建的初衷为HITSZ的数据结构实验提供课程代码的编写和测评，以此方便学生实验时得到实时的反馈，此后陆续被多个实验课程采用。本人在项目开发过程中，主要承担了OJ部分和题目部分的后端开发。</p><span id="more"></span><h2 id="需求分析">需求分析</h2><p>将实验平台的功能分为核心业务和底层服务两大模块。</p><p>核心业务模块：</p><ul><li>OJ评测模块</li><li>用户管理模块(涉及验证)</li><li>作业提交模块</li></ul><p>底层服务模块:</p><ul><li>日志记录</li><li>限流保护</li><li>用户反馈</li><li>评论/题解</li><li>数据库请求（题目、题解、评论等）</li></ul><h2 id="技术栈">技术栈</h2><ul><li>Springboot 后端开发框架，简化应用的搭建和开发过程</li><li>Redis 非关系型数据库，可用于缓存，保存非持久化数据</li><li>MySQL 关系型数据库管理系统</li><li>MyBatis 持久层框架，简化数据库访问</li><li>Java 后端开发语言</li><li>七牛云 用户头像（图片）存储</li><li>Vue 构建界面的JavaScript框架，提供了一套声明式的、组件化的编程模型</li><li>ElementUI Vue组件集合</li><li>JavaScript web脚本语言，动态更新内容</li><li>Node.js javascript运行时环境</li></ul><h2 id="开发工具">开发工具</h2><ul><li>IDEA 后端开发</li><li>WebStorm 前端开发</li><li>Xftp 服务器间文件传输</li><li>Postman 后端接口测试工具，模拟发送http请求</li></ul><h2 id="相关技术原理">相关技术原理</h2><h3 id="沙箱">沙箱</h3><p>github仓库: https://github.com/criyle/go-judge</p><h4 id="系统架构">系统架构</h4><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-code">+------------------------------------------------------------------------+</span><br><span class="hljs-section">| 传输层 (HTTP / WebSocket / FFI / ...)                                  |</span><br><span class="hljs-section">+------------------------------------------------------------------------+</span><br><span class="hljs-section">| 工作协程 (环境池 和 环境生产者)                                        |</span><br><span class="hljs-section">+-----------------------------------------------------------+------------+</span><br><span class="hljs-section">| 运行环境                                                  | 文件存储   |</span><br><span class="hljs-section">+--------------------+----------------+---------------------+------+-----+</span><br><span class="hljs-section">| Linux (go-sandbox) | Windows (winc) | macOS (app sandbox) | 内存 | 磁盘|</span><br><span class="hljs-section">+--------------------+----------------+---------------------+------+-----+</span><br></code></pre></td></tr></table></figure><p>运行的代码以文件形式存储在沙箱服务器的内存/磁盘，在linux上，创建功能受限的容器，使代码在容器内运行，避免破坏环境。通过发送HTTP请求使沙箱执行相应操作，在受限的环境中运行程序，具体API接口如下一部分所示</p><h4 id="rest-api-接口">REST API 接口</h4><p>沙箱服务提供 REST API 接口来在受限制的环境中运行程序。本质是 <code>envexec</code> 的简单封装。</p><ul><li>/run POST 在受限制的环境中运行程序（下面有例子）</li><li>/file GET 得到所有在文件存储中的文件 ID 到原始命名映射</li><li>/file POST 上传一个文件到文件存储，返回一个文件 ID 用于提供给 /run 接口</li><li>/file/:fileId GET 下载文件 ID 指定的文件</li><li>/file/:fileId DELETE 删除文件 ID 指定的文件</li><li>/ws /run 接口的 WebSocket 版</li><li>/metrics 提供 prometheus 版监控 (使用 <code>ES_ENABLE_METRICS=1</code> 环境变量开启)</li><li>/debug 提供 go 语言调试接口 (使用 <code>ES_ENABLE_DEBUG=1</code> 环境变量开启)</li><li>/version 得到本程序编译版本和 go 语言运行时版本</li></ul><h4 id="run-接口返回状态">/run 接口返回状态</h4><ul><li>Accepted: 程序在资源限制内正常退出</li><li>Memory Limit Exceeded: 超出内存限制</li><li>Time Limit Exceeded:<ul><li>超出 <code>timeLimit</code> 时间限制</li><li>或者超过 <code>clockLimit</code> 等待时间限制</li></ul></li><li>Output Limit Exceeded:<ul><li>超出 <code>pipeCollector</code> 限制</li><li>或者超出 <code>-output-limit</code> 最大输出限制</li></ul></li><li>File Error:<ul><li><code>copyIn</code> 指定文件不存在</li><li>或者 <code>copyIn</code> 指定文件大小超出沙箱文件系统限制</li><li>或者 <code>copyOut</code> 指定文件不存在</li></ul></li><li>Non Zero Exit Status: 程序用非 0 返回值退出</li><li>Signalled: 程序收到结束信号而退出（例如 <code>SIGSEGV</code>）</li><li>Dangerous Syscall: 程序被 <code>seccomp</code> 过滤器结束</li><li>Internal Error:<ul><li>指定程序路径不存在</li><li>或者容器创建失败<ul><li>比如使用非特权 docker</li><li>或者在个人目录下以 root 权限运行</li></ul></li><li>或者其他错误</li></ul></li></ul><h4 id="接口定义">接口定义</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">interface</span> <span class="hljs-title class_">Cmd</span> &#123;<br>    args: string[]; <span class="hljs-comment">// 程序命令行参数</span><br>    env?: string[]; <span class="hljs-comment">// 程序环境变量</span><br><br>    <span class="hljs-comment">// 指定 标准输入、标准输出和标准错误的文件</span><br>    files?: (LocalFile | MemoryFile | PreparedFile | Pipe | <span class="hljs-literal">null</span>)[];<br>    tty?: <span class="hljs-type">boolean</span>; <span class="hljs-comment">// 开启 TTY （需要保证标准输出和标准错误为同一文件）同时需要指定 TERM 环境变量 （例如 TERM=xterm）</span><br><br>    <span class="hljs-comment">// 资源限制</span><br>    cpuLimit?: number;     <span class="hljs-comment">// CPU时间限制，单位纳秒</span><br>    clockLimit?: number;   <span class="hljs-comment">// 等待时间限制，单位纳秒 （通常为 cpuLimit 两倍）</span><br>    memoryLimit?: number;  <span class="hljs-comment">// 内存限制，单位 byte</span><br>    stackLimit?: number;   <span class="hljs-comment">// 栈内存限制，单位 byte</span><br>    procLimit?: number;    <span class="hljs-comment">// 线程数量限制</span><br>    strictMemoryLimit?: <span class="hljs-type">boolean</span>; <span class="hljs-comment">// 开启严格内存限制 （仅 Linux，设置 rlimit 内存限制）</span><br><br>    <span class="hljs-comment">// 在执行程序之前复制进容器的文件列表</span><br>    copyIn?: &#123;[dst:string]:LocalFile | MemoryFile | PreparedFile&#125;;<br><br>    <span class="hljs-comment">// 在执行程序后从容器文件系统中复制出来的文件列表</span><br>    <span class="hljs-comment">// 在文件名之后加入 &#x27;?&#x27; 来使文件变为可选，可选文件不存在的情况不会触发 FileError</span><br>    copyOut?: string[];<br>    <span class="hljs-comment">// 和 copyOut 相同，不过文件不返回内容，而是返回一个对应文件 ID ，内容可以通过 /file/:fileId 接口下载</span><br>    copyOutCached?: string[];<br>    <span class="hljs-comment">// 指定 copyOut 复制文件大小限制，单位 byte</span><br>    copyOutMax: number;<br>&#125;<br><br><span class="hljs-keyword">enum</span> <span class="hljs-title class_">Status</span> &#123;<br>    Accepted,            <span class="hljs-comment">// normal</span><br>    MemoryLimitExceeded, <span class="hljs-comment">// mle</span><br>    TimeLimitExceeded,   <span class="hljs-comment">// tle</span><br>    OutputLimitExceeded, <span class="hljs-comment">// ole</span><br>    FileError,           <span class="hljs-comment">// fe</span><br>    RuntimeError,        <span class="hljs-comment">// re</span><br>    DangerousSyscall,    <span class="hljs-comment">// dgs</span><br>    InternalError,       <span class="hljs-comment">// system error</span><br>&#125;<br><br><br><span class="hljs-keyword">interface</span> <span class="hljs-title class_">Request</span> &#123;<br>    requestId?: string; <span class="hljs-comment">// 给 WebSocket 使用</span><br>    cmd: Cmd[];<br>    pipeMapping: PipeMap[];<br>&#125;<br><br><span class="hljs-keyword">interface</span> <span class="hljs-title class_">Result</span> &#123;<br>    status: Status;<br>    error?: string; <span class="hljs-comment">// 详细错误信息</span><br>    exitStatus: number; <span class="hljs-comment">// 程序返回值</span><br>    time: number;   <span class="hljs-comment">// 程序运行 CPU 时间，单位纳秒</span><br>    memory: number; <span class="hljs-comment">// 程序运行内存，单位 byte</span><br>    runTime: number; <span class="hljs-comment">// 程序运行现实时间，单位纳秒</span><br>    <span class="hljs-comment">// copyOut 和 pipeCollector 指定的文件内容</span><br>    files?: &#123;[name:string]:string&#125;;<br>    <span class="hljs-comment">// copyFileCached 指定的文件 id</span><br>    fileIds?: &#123;[name:string]:string&#125;;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="rsa加密原理">RSA加密原理</h3><p>RSA是经典的非对称加密算法，拥有两个密钥：公钥和私钥。</p><h4 id="公钥和私钥的生成">公钥和私钥的生成</h4><ol type="1"><li>准备两个非常大的素数<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>。</li><li>利用字符串模拟计算大素数<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span> 的乘积。</li><li>同样方法计算<span class="math inline">\(m = (p-1)(q-1)\)</span>，这里的<span class="math inline">\(m\)</span>为<span class="math inline">\(n\)</span>的欧拉函数。</li><li>找到一个数<span class="math inline">\(e(1&lt;e&lt;m)\)</span>，满足<span class="math inline">\(gcd(m,e)=1\)</span>(<span class="math inline">\(m, e\)</span>互素)。</li><li>计算<span class="math inline">\(e\)</span>在模<span class="math inline">\(m\)</span>上的逆元<span class="math inline">\(d\)</span>，即满足$ ed  mod  m = 1$。</li><li>公钥和私钥生成完毕，<span class="math inline">\((n,e)\)</span>为公钥，<span class="math inline">\((n,d)\)</span>为私钥。</li></ol><h4 id="加密">加密</h4><p>对于明文<span class="math inline">\(x\)</span>，用公钥<span class="math inline">\((n,e)\)</span>对<span class="math inline">\(x\)</span>加密后得到的密文y为：<span class="math inline">\(y = x^e \ mod \ n\)</span>。</p><h4 id="解密">解密</h4><p>对于密文<span class="math inline">\(y\)</span>，用私钥<span class="math inline">\((n,d)\)</span>对<span class="math inline">\(y\)</span>解密后得到的明文x为：<span class="math inline">\(x = y^d \ mod \ n\)</span>。</p><h2 id="主要功能实现思路">主要功能实现思路</h2><h3 id="oj在线评测">OJ在线评测</h3><p>OJ评测部分的流程大致如下图所示： <img src="/img/HITSZOJ数据结构课程实验平台/oj-pipeline.png" alt="OJ评测流程图" /></p><ol type="1"><li>根据时间创建文件，将提交的代码以文件形式存入沙箱。</li><li>在Cmd类对象中填入运行代码所需的工具链，如c语言对应<code>gcc</code>。</li><li>将代码按沙箱规定的输入格式进行转化。</li><li>向沙箱请求<code>/run</code>接口，发送HTTP请求，并对沙箱返回的结果进行解码。</li><li>若返回状态不是<code>Accepted</code>，则代码执行失败，将错误输出返回给用户，提示用户修改代码。</li><li>若返回状态为<code>Accepted</code>，则代码执行成功，返回代码执行的时间，所占用的内存，输出等信息。</li><li>删除存放在沙箱中的代码文件。</li><li>将用户提交的程序的输出和数据库中对应题目的正确答案进行对比，若一致，则创建提交记录，其状态为成功；否则创建提交记录，其状态为对应的失败原因。</li></ol><h3 id="用户管理--邮箱验证">用户管理--邮箱验证</h3><ol type="1"><li>随机产生6位验证码（包括字母/数字），并将其按用户对应的键存储到Redis。</li><li>只用JavaMailSender将验证码和提示信息发送给用户。</li><li>用户在页面输入验证码，提交，验证码由前端通过接口传到后端。</li><li>后端验证用户提交的验证码是否与Redis中存储的一致，若一致，则验证通过；若不一致，或Redis中不存在对应验证码（过期），则验证失败。</li></ol><div class="note note-success">            <p>为什么使用Redis作为验证码的存储方式？</p><ul><li>Redis可设置过期时长，与验证码的时效性相吻合。</li><li>验证码是临时的数据，不需要持久化。</li><li>数据运行在内存中，唯有持久化时才写到磁盘中，读写性能高。</li></ul>          </div><h3 id="用户管理--登录">用户管理--登录</h3><ol type="1"><li>首先验证账户是否存在，前端发送用户账户名，后端生成<code>验证码a</code>，并以一定的名称+用户id作为键存入Redis（有效期5min），将<code>验证码a</code>和查询数据库所得的用户id返回给前端。若用户id不存在，则登录失败。</li><li>前端将用户输入的密码+第1步返回的<code>验证码a</code>拼接，用SHA256加密后发送给后端。后端将正确密码+<code>验证码a</code>拼接，用SHA256加密，和前端传来的密文进行比较。若一致，则登录成功；否则密码不正确，登录失败。</li><li>删除Redis中存储的<code>验证码a</code>。</li><li>根据用户名、用户id、权限级别，创建<code>验证码b</code>，以<code>online_&#123;id&#125;</code>作为键存在Redis中，7天有效。（即意味着用户登陆后7天有效，无需每次使用时重新登录）。</li></ol><h3 id="用户管理--修改密码">用户管理--修改密码</h3><h4 id="旧密码已知直接修改">1 旧密码已知，直接修改</h4><ol type="1"><li>验证账户是否存在。前端发送用户账户名，后端生成<code>验证码a</code>（有效期5min），并以一定的名称+用户id作为键存入Redis，将<code>验证码a</code>和查询数据库所得的用户id返回给前端。若用户id不存在，则验证失败。</li><li>验证旧密码是否正确。前端将用户输入的旧密码+第1步返回的<code>验证码a</code>拼接，用SHA256加密后发送给后端。后端将正确旧密码+<code>验证码a</code>拼接，用SHA256加密，和前端传来的密文进行比较。若一致，则旧密码验证成功；否则密码不正确，旧密码验证失败，修改密码失败，操作终止。</li><li>删除Redis中存储的<code>验证码a</code>。</li><li>若旧密码验证成功，生成<code>验证码b</code>（有效期5min），并以一定的名称+用户id作为键存入Redis（一段时间后失效），标志旧密码验证成功。</li><li>若旧密码验证成功，返回用于加密的RSA公钥。</li><li>修改新密码。若<code>验证码b</code>在redis中不存在，则修改失败，退出。</li><li>若<code>验证码b</code>在redis中存在，接受前端发送的用公钥加密后的密码，用RSA的私钥对加密后的密码解密，存入数据库。</li></ol><h4 id="旧密码遗忘通过邮箱验证修改">2 旧密码遗忘，通过邮箱验证，修改</h4><ol type="1"><li>验证账户是否存在。前端发送用户账户名，后端生成<code>验证码a</code>，并以一定的名称+用户id作为键存入Redis。</li><li>将第1步生成的<code>验证码a</code>发送到用户的邮箱。</li><li>用户查看邮件后在页面输入收到的验证码。若用户输入的验证码与redis中存储的一致，则将<code>验证码a</code>删除并生成<code>验证码b</code>，一定的名称+用户id作为键存入Redis，并返回RSA公钥。若用户输入的验证码与redis中存储的不一致，提示用户验证码不正确。</li><li>若用户邮箱验证成功（<code>验证码b</code>在redis中存在），则用RSA私钥解码前端传来的加密后的新密码，更新数据库，删除<code>验证码b</code>。</li></ol><section class="footnotes"><h2>参考</h2><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/450180396">RSA——经典的非对称加密算法</a> <a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://blog.csdn.net/u011583927/article/details/80905740">SHA256算法原理详解</a> <a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://github.com/criyle/go-judge">go-judge沙箱服务</a> <a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Projects</category>
      
    </categories>
    
    
    <tags>
      
      <tag>oj</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
