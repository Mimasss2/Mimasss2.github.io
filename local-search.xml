<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>NSCSCC2022 龙芯杯参赛总结</title>
    <link href="/2023/01/22/%E9%BE%99%E8%8A%AF%E6%9D%AF%E5%8F%82%E8%B5%9B%E6%80%BB%E7%BB%93/"/>
    <url>/2023/01/22/%E9%BE%99%E8%8A%AF%E6%9D%AF%E5%8F%82%E8%B5%9B%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<div class="note note-info">            <p>我参加的是2022年龙芯杯个人赛，从2022年2月左右开始准备，到2022年8月完赛。以下为我的参赛历程与感想。</p>          </div><!--more--><h3 id="赛事简介">赛事简介</h3><p>全称 ： “龙芯杯”全国大学生计算机系统能力培养大赛</p><p>全国大学生计算机系统能力大赛（National Student Computer System Capability Challenge, NSCSCC）是由教育部高等学校计算机类专业教学指导委员会和系统能力培养研究专家组共同发起，以学科竞赛推动专业建设和计算机领域创新人才培养体系改革、培育我国高端芯片及核心系统的技术突破与产业化后备人才为目标,面向高校大学生举办的全国性大赛。</p><p>大赛共分3个赛道：CPU、编译系统、操作系统。其中，CPU赛道即“龙芯杯”竞赛。</p><p>“龙芯杯”竞赛分3个赛道：MIPS团队赛、MIPS个人赛 和 LoongArch挑战赛。</p><ul><li><p>MIPS团队赛 ： 开发支持32位MIPS基准指令集的简易计算机系统。加分项：运行操作系统、实现加速器、设计可演示的应用</p></li><li><p>MIPS个人赛 ： 开发支持32位MIPS基准指令集的简易计算机系统。完成三级功能测试（最多22条指令），支持SRAM、UART，运行监控程序。 总成绩 = 功能测试 得分 + 性能测试 得分</p></li><li><p>LoongArch挑战赛 ： 开发支持LoongArch32 Reduced指令集的简易计算机系统，并在自己编写的CPU上启动Linux操作系统。 总成绩 = 70% * benchmark基准测试成绩 + 30% * 系统展示及答辩</p></li></ul><p>*详细内容可参考<a href="https://github.com/loongson-education/nscscc-wiki">龙芯官方wiki</a></p><h3 id="个人赛要做什么">个人赛要做什么？</h3><ul><li>一个支持MIPS基准指令集的MIPS位系统</li><li>使用实验板上的SRAM作为存储</li><li>CPU核能够通过接口与各I/O设备互联通信</li><li>支持MIPS-C3指令集（总共39条指令左右），运行提供的MIPS监控程序</li><li>决赛：使用汇编语言现场写算法题，编译后放到自己做的CPU上跑</li><li>......</li></ul><h3 id="前期准备">前期准备</h3><p>2022NSCSCC的时间线如下，仅供参考。 <img src="/img/龙芯杯参赛总结/2022timeline.png" /></p><div class="note note-secondary">            <p>我们学校组织备赛开始得较早，在2021年12月底即组织了宣讲和预报名，年后即开始了每周进度汇报会。虽然前期的进度不算快，但每周前进一小步，还是积累了不少东西</p>          </div><p>理论部分，首先阅读《计算机组成与设计》学习设计相关的理论知识，之后跟着雷思磊的《自己动手写cpu》实现一个支持基本的mips指令的cpu。我一开始把书上写的都实现了一遍，之后再看着官方要求的指令把不相关的删掉了，实际上可以只实现需要的部分。</p><p>具体针对比赛所需，我阅读了龙芯官方发的前几届参赛选手的经验指南，但很多写得很长，讲了很多专业术语，最开始看的时候晕头转向的。后来还是先根据官方的技术指南，先明确需求，需要实现什么，再针对性得根据这些看还需要实现什么，在哪些部分可以提高性能。</p><h3 id="架构与技术概要">架构与技术概要</h3><p>系统总体架构采取顺序单发射五级流水cpu，支持延迟槽。支持uart串口通信，支持sram，其中访存只占据一个周期。较短的访存时间对很大程度上限制了cpu的频率。最后最高可以跑到63.34M。</p><figure><img src="/img/龙芯杯参赛总结/cpu整体架构.png" alt="cpu总体架构" /><figcaption aria-hidden="true">cpu总体架构</figcaption></figure><p>cpu 核心采用顺序单发射五级流水线，各流水线模块关系如下图所示。</p><figure><img src="/img/龙芯杯参赛总结/cpu核心架构.png" alt="cpu核心架构" /><figcaption aria-hidden="true">cpu核心架构</figcaption></figure><h3 id="参赛作品亮点">参赛作品亮点</h3><p>采用wallace tree实现两周期乘法器，大大减少了乘法模块的资源消耗，并减少了因dsp乘法连线过长导致的关键路径。</p><p>单周期访问sram，在频率较低时极大得减少了因访存而导致的流水线停顿，大大提高了系统的ipc。 值得一提的是，在优化阶段我曾尝试多周期访存+cache，但仔细分析后发现，这种配置下如果要达到和单周期五级流水相似的性能，需要至少110+M的频率，且多周期访存产生的停顿意味着需要改变延迟槽判断的方式等等一系列细节逻辑，且80+M时就会因数据前递的较长连线而产生关键路径。最后权衡系统性能，系统复杂度（稳定度），以及时间分配（练习汇编算法），还是采用了顺序五级流水的基础结构。</p><p>系统运行流畅，停顿概率很低，仅在乘法后RAW-1，访存取指同时访问imem两种情况下才会停顿。</p><h3 id="作品最终完成度">作品最终完成度</h3><p>比赛要求任务全部完成，实现了MIPS C3指令集总共39条指令，支持uart串口通信，sram访存。性能测试结果为: STREAM用时0.099s, MATRIX用时0.141s, CRYPTONIGHT用时0.364s, 总计0.604s。决赛时在规定时间内完成了二分查找的汇编算法，并在自己设计的cpu上跑通。</p><h3 id="备赛经验及建议">备赛经验及建议</h3><p><strong>备赛前期：</strong>阅读《计算机组成与设计》，《计算机体系结构：量化研究方法》两本经典书籍学习所需的基本原理。阅读《自己动手写cpu》，并上手写代码，实现一个基本版的cpu。</p><p><strong>备赛冲刺阶段：</strong>可以在初赛前一个半月左右着手开始优化系统，不建议把战线拉太长，不然中间阶段不知道做什么/迷失方向没人讨论的时候会很痛苦。优化前先仔细调研优化方法，及其在比赛任务上的优化效率。可以参考GitHub上之前参赛选手开源出的作品代码作为参考。不用各种优化方法兼顾，重点攻克对于评分任务提升较大，稳定性较高的方案。</p><p><strong>备赛后期：</strong>初赛结束后还有两周左右的时间到决赛，不建议再修改cpu设计，因为时间很匆忙，不一定赶得出来一个稳定版，而且决赛任务不仅仅看重cpu性能。建议放松一两天后着力准备决赛的编程任务。决赛编程任务属于中等难度的算法题，但需要用汇编实现。参考准备路线：跟着<a href="https://github.com/changgyhub/leetcode_101">LeetCode 101</a> 这本算法书练习经典算法。 到c++容器那章前基本就够了，练习的编程语言任意，顺手就好，用高级语言就行，方便在leetcode上在线评测。之后可以再看看University of Alberta 的CMPUT229这门课的<a href="https://github.com/cmput229/MIPSPatterns">MIPS汇编教程</a> , 掌握高级语言流程结构和汇编语言转换的基本方法，用MIPS汇编实现几个经典的算法，如快排，二分等等，并在Mars和自己的cpu上依次验证。</p><p><strong>决赛技巧：</strong>个人赛决赛仍然采用线上测评平台，由于比赛时间有限，同时在线人数较多，决赛时线上编译速度很慢，工程文件改动后重新编译至少需要20-30min，运行测试也需要排队5min左右。但仅仅修改汇编代码只会重新编译汇编代码，工程文件不再重新编译，只需1分钟左右就可在gitlab上编译完成，。因此强烈建议在决赛时不要修改内核，节省时间。同时，可以在决赛前在多个git分支上准备好多个不同频率的工程版本（比如60M稳定版用于测试汇编代码正确性，频率再高的版本用来降低时间刷分），汇编程序写好后可以分别写到这些分支上，就可以在短时间内得到多个在线编译通过的不同频率的提交文件，能够高效刷分测试。（我决赛时只准备了稳定版本的，后面时间比较紧张就没有再提高频率，有点遗憾。）</p><p>最后，十分感谢老师们给我们提供的良好的交流机会，督促我们不断优化性能，为我们提供了优越的备赛交流环境。也非常感谢一同参加比赛的各位大佬十分耐心回答我的问题以及在交流碰撞出的新思路！</p>]]></content>
    
    
    <categories>
      
      <category>“Projects”</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NSCSCC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>无监督句子多样性评价指标</title>
    <link href="/2023/01/21/NLP_sentence_diversity_evaluation/"/>
    <url>/2023/01/21/NLP_sentence_diversity_evaluation/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在项目推进过程中，产生了对生成句子多样性进行评价、筛选的需求。遂调研了部分现有的无监督句子多样性的评价指标，以备参考使用。 <span id="more"></span></p></blockquote><h2 id="bertscore">BERTScore</h2><p>paper: <a href="https://arxiv.org/abs/1904.09675v3">BERTSCORE: EVALUATING TEXT GENERATION WITH BERT</a></p><p><img src="/img/nlp_sentence_diversity/bertscore.png" /></p><p>每个词找另一个句子中和它内积最大的词</p><p><span class="math display">\[R_{BERT} = \frac{1}{|x|} \underset{x_i \in x}{\Sigma} \underset{\hat{x}\in \hat{x}} {max}  x_i^{T} \hat{x_j},\quadP_{BERT} = \frac{1}{\|\hat{x}\|} \underset{\hat{x_i} \in \hat{x}}{\Sigma} \underset{\hat{x} \in \hat{x}}{max} x_i^{T} \hat{x_j}, \quadF_{BERT} = 2\frac{P_{BERT}\cdot R_{BERT}}{P_{BERT} + R_{BERT}}\]</span></p><h4 id="importance-weighting">Importance Weighting</h4><p>based on inverse document frequency</p><p><span class="math display">\[idf(w) = -\log \frac{1}{M} \Sigma_{i=1}^{M} I [w \in x^{(i)}]\]</span></p><h4 id="rescaling">rescaling</h4><p><span class="math display">\[\hat{R}_{BERT} = \frac{R_{BERT} - b}{1-b}\]</span></p><p>b: empirical lower bound, calculated using Common Crawl monolingual datasets</p><h4 id="comparison">Comparison</h4><p>machine translation evalution -&gt; <span class="math inline">\(F_{BERT}\)</span></p><p>text generation in Eglish -&gt; 24-layer <span class="math inline">\(RoBERTa_{large}\)</span></p><p>non-English language -&gt; <span class="math inline">\(BERT_{multi}\)</span></p><h2 id="bleurt">BLEURT</h2><p>paper: <a href="https://arxiv.org/abs/2004.04696">BLEURT: Learning Robust Metrics for Text Generation. ACL 2020</a></p><h4 id="architecture">Architecture</h4><p>Bert + Linear Head</p><h4 id="pre-training-scheme">pre-training scheme</h4><p>random perturbations of Wikipedia sentences augmented with a diverse set of lexical and semantic-level supervision signals</p><ul><li>mask-filling with BERT -&gt; lexical alterations</li><li>backtranslation</li><li>randomly dropping out words -&gt; to recognize void preditions and sentence truncation in NLG systems</li></ul><p>pretraining metrics: weighted sum of previous metrics</p><h3 id="bartscore">BARTScore</h3><p>paper: <a href="https://arxiv.org/abs/2106.11520">BARTSCORE: Evaluating Generated Text as Text Generation</a></p><p>ExplainaBoard：http://explainaboard.nlpedia.ai/leaderboard/task-meval/</p><figure><img src="/img/nlp_sentence_diversity/bart_board.png" alt="image-20221128102518705" /><figcaption aria-hidden="true">image-20221128102518705</figcaption></figure><h4 id="evaluation-perspectives">evaluation perspectives:</h4><ul><li>Informativeness</li><li>Relevance</li><li>Fluency</li><li>Coherence</li><li>FActuality</li><li>Semantic Coverage</li><li>Adequacy</li></ul><h4 id="bartscore-1">BARTScore</h4><p><span class="math display">\[BARTSCORE = \Sigma_{t=1}^{m} \omega_t \log p(y_t | y_{&lt;t}, x, \theta)\]</span></p><p>using prompt to augment metrics</p><p>没太看明白，一开始列了一堆指标，最后又只有一个BARTScore。看了眼ExplainaBoard，猜测可能是评判的任务/输入数据对<span class="math inline">\(\{x,y\}\)</span>不同，BARTScore体现出的评判句子的方面就不一样</p><h2 id="moverscore">MoverScore</h2><p>MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance. <a href="https://arxiv.org/abs/1909.02622">link</a></p><h4 id="moverdistance">MoverDistance</h4><p><span class="math display">\[WMD(x^n, y^n) := \underset{F \in R^{|x^n| \times |y^n|}}{min} &lt;C,F&gt;,\quad s.t. F1 = f_{x^n}, F^T 1 = f_{y^n}\]</span></p><p><span class="math inline">\(C_{ij} = d(x_i^n, y_j^n)\)</span>, the distance between the i-th n-gram of x and the j-th n-gram of y</p><p><span class="math inline">\(F\)</span>: transportation flow matrix, <span class="math inline">\(F_{ij}\)</span> denoting the amount of flow traveling from the ith n-gram <span class="math inline">\(x_i^n\)</span> in <span class="math inline">\(x^n\)</span> to the j-th n-gram <span class="math inline">\(y_j^n\)</span> in <span class="math inline">\(y^n\)</span>.</p><p><span class="math inline">\(&lt;C,F&gt; = sum(C \odot F)\)</span></p><p><span class="math inline">\(d(x_i^n, y_j^n)\)</span> Euclidean distance</p><p><span class="math inline">\(f_{x^n_i} = \frac{1}{Z} \Sigma_{k=i}^{i+n-1} idf(x_k)\)</span></p><h4 id="vs-bertscore">vs BERTScore</h4><figure><img src="/img/nlp_sentence_diversity/bartscore_vs_bertscore.png" alt="image-20221128093223272" /><figcaption aria-hidden="true">image-20221128093223272</figcaption></figure><p>对于某个词，BERTScore算原句子中与它最相似的词的相似度（内积），而MoverScore算这个词和所有其他词的加权内积和，权重（即公式中的<span class="math inline">\(F\)</span>）通过idx算</p><h2 id="embedding-average">Embedding Average</h2><p>直接计算生成文本和参考文本中词向量的平均值作为文本的向量表示，然后计算两个文本的余弦相似度作为生成文本和参考文本的相似度：</p><p><span class="math display">\[\bar{e_r} = \frac{\Sigma_{\omega \in r} e_{\omega}}{| \Sigma_{\omega &#39; \in r} e_{\omega &#39;}|}\]</span> <span class="math display">\[EA := cos(\bar{e_r}, \bar{e_{\hat{r}}})\]</span></p><h2 id="perplexity">Perplexity</h2><h2 id="p.s.">p.s.</h2><p>很多现有的评价生成的文本的指标是基于Machine Translation任务的，计算原句子和翻译句子的相似度/匹配度。</p><h5 id="评价句子相似度的一些指标">评价句子相似度的一些指标</h5><ul><li><a href="https://aclanthology.org/S17-2001/">Semantic Textual Similarity</a></li><li><a href="https://aclanthology.org/W17-4767/">MEANT 2.0</a></li><li><a href="https://arxiv.org/abs/2109.06379">Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation</a></li><li>…</li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git cheatsheet</title>
    <link href="/2022/12/09/git_cheatsheet/"/>
    <url>/2022/12/09/git_cheatsheet/</url>
    
    <content type="html"><![CDATA[<p>A git command cheatsheet.</p><p><span id="more"></span></p><h4 id="create-repo">1 create repo</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cli">git init<br></code></pre></td></tr></table></figure><p>初始化当前目录为git仓库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cli">git clone &lt;url&gt; <br>git clone &lt;url&gt; &lt;dir&gt; # 将仓库克隆到指定的目录<br></code></pre></td></tr></table></figure><p>从<code>url</code>克隆仓库</p><h4 id="modify-and-commit">2 modify and commit</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cli">git add &lt;filename&gt; # 添加名为filename的文件的变化<br>git add . # 添加当前目录下及其子目录下的所有文件的变化<br></code></pre></td></tr></table></figure><p>添加文件到暂存区</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cli">git commit -m &lt;version comment&gt; # 将当前版本提交，并添加注释`&lt;version comment&gt;`<br></code></pre></td></tr></table></figure><p>提交暂存区到仓库。</p>]]></content>
    
    
    <categories>
      
      <category>Cheatsheet</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
